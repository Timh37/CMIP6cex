{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204334ce-ab38-445f-aad0-ae91d07b400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7264/2781798931.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fnmatch\n",
    "import xarray as xr\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time\n",
    "from sklearn.decomposition import PCA\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() # equivalent to fsspec.fs('gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edb6074-9387-42a2-9560-3fe9d3b1334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 9 #n by n degree grid around each TG\n",
    "cmip6_resolution = 1.5\n",
    "\n",
    "num_grid_cells = int(grid_size/cmip6_resolution)\n",
    "\n",
    "mlr_coefs = xr.open_dataset('/home/jovyan/CMIP6cex/cmip6_processing/gssr_mlr_coefs_1p5_9deg_gesla2.nc') #load MLR coefficients at TGs\n",
    "era5_pcs = xr.open_dataset('/home/jovyan/CMIP6cex/cmip6_processing/era5_pca_components_1p5_9deg_gesla2.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ccba6-255a-464b-9c64-3ff2803720ee",
   "metadata": {},
   "source": [
    "Loop over timeseries of `psl` & `sfcWind` at common 1.5 by 1.5 degree grid and open them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19544d38-afd3-4cb3-8dad-cde0a1c2e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_dir = '/home/jovyan/CMIP6cf/output/subsetted_forcing/'\n",
    "var1 = 'psl'\n",
    "var2 = 'sfcWind'\n",
    "\n",
    "var1_dir = 'leap-persistent/timh37/CMIP6/timeseries/'+var1+'_europe'\n",
    "var2_dir = 'leap-persistent/timh37/CMIP6/timeseries/'+var2+'_europe'\n",
    "\n",
    "output_dir = 'leap-persistent/timh37/CMIP6/timeseries/surge_tgs'\n",
    "\n",
    "var1_models = [k.split('/')[-1] for k in fs.ls(var1_dir) if k.startswith('.')==False]\n",
    "var2_models = [k.split('/')[-1] for k in fs.ls(var2_dir) if k.startswith('.')==False]\n",
    "\n",
    "models = [k for k in var1_models if k in var2_models]\n",
    "ddict = defaultdict(dict)\n",
    "\n",
    "for source_id in models:\n",
    "    var1_model_path = os.path.join(var1_dir,source_id)\n",
    "    var2_model_path = os.path.join(var2_dir,source_id)\n",
    "    \n",
    "    var1_exps = [s.split('/')[-1].split('_')[-1][0:-5] for s in fs.ls(var1_model_path) if s.startswith('.')==False] \n",
    "    var2_exps = [s.split('/')[-1].split('_')[-1][0:-5] for s in fs.ls(var2_model_path) if s.startswith('.')==False]\n",
    "    experiment_ids = list(set(var1_exps) & set(var2_exps))\n",
    "    \n",
    "    for experiment_id in set(experiment_ids): #for each experiment_id, open the datasets, concatenating all realizations:\n",
    "        #load data:\n",
    "        fn = fnmatch.filter(fs.ls(var1_model_path),'*'+experiment_id+'*')[0]\n",
    "        fn = fn.split('/')[-1]\n",
    "        \n",
    "        var1_var2_data = xr.open_mfdataset((os.path.join('gs://',var1_model_path,fn),os.path.join('gs://',var2_model_path,fn)),engine='zarr',chunks={'member_id':1,'time':100000,'longitude':5})\n",
    "        \n",
    "        ddict[fn.replace('.zarr','')] = var1_var2_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2a215-c34a-4a4e-96f3-3838baf7485d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate predictor data and multiply with regression coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5857398e-34fc-48b2-86f7-2293bf829ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde9480a2e7c4e9a955d28ffd54d580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beadb83779df4a02a4c5fefc3dc4f8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#concatenate & stack normalized forcing variables to data array with shape (time,(4 variables * grid_size * grid_size))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m predictors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictors[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfcWind\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfcWind_sqd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfcWind_cbd\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_array(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor_var\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 35\u001b[0m predictors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpredictors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictor_var\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlon_around_tg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictor_var\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon_around_tg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat_around_tg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcreate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#compute surges from predictors\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m#initialize\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataarray.py:2798\u001b[0m, in \u001b[0;36mDataArray.stack\u001b[0;34m(self, dimensions, create_index, index_cls, **dimensions_kwargs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;28mself\u001b[39m: T_DataArray,\n\u001b[1;32m   2735\u001b[0m     dimensions: Mapping[Any, Sequence[Hashable]] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2738\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdimensions_kwargs: Sequence[Hashable],\n\u001b[1;32m   2739\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_DataArray:\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;124;03m    Stack any number of existing dimensions into a single new dimension.\u001b[39;00m\n\u001b[1;32m   2742\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;124;03m    DataArray.unstack\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2798\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdimensions_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:5194\u001b[0m, in \u001b[0;36mDataset.stack\u001b[0;34m(self, dimensions, create_index, index_cls, **dimensions_kwargs)\u001b[0m\n\u001b[1;32m   5192\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   5193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_dim, dims \u001b[38;5;129;01min\u001b[39;00m dimensions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 5194\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stack_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:5110\u001b[0m, in \u001b[0;36mDataset._stack_once\u001b[0;34m(self, dims, new_dim, index_cls, create_index)\u001b[0m\n\u001b[1;32m   5108\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[d] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m vdims]\n\u001b[1;32m   5109\u001b[0m exp_var \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mset_dims(vdims, shape)\n\u001b[0;32m-> 5110\u001b[0m stacked_var \u001b[38;5;241m=\u001b[39m \u001b[43mexp_var\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mnew_dim\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5111\u001b[0m new_variables[name] \u001b[38;5;241m=\u001b[39m stacked_var\n\u001b[1;32m   5112\u001b[0m stacked_var_names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/variable.py:1777\u001b[0m, in \u001b[0;36mVariable.stack\u001b[0;34m(self, dimensions, **dimensions_kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_dim, dims \u001b[38;5;129;01min\u001b[39;00m dimensions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 1777\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stack_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/variable.py:1743\u001b[0m, in \u001b[0;36mVariable._stack_once\u001b[0;34m(self, dims, new_dim)\u001b[0m\n\u001b[1;32m   1740\u001b[0m reordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m*\u001b[39mdim_order)\n\u001b[1;32m   1742\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m reordered\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mlen\u001b[39m(other_dims)] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m-> 1743\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreordered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m new_dims \u001b[38;5;241m=\u001b[39m reordered\u001b[38;5;241m.\u001b[39mdims[: \u001b[38;5;28mlen\u001b[39m(other_dims)] \u001b[38;5;241m+\u001b[39m (new_dim,)\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Variable(new_dims, new_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/duck_array_ops.py:337\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(array, shape)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(array, shape):\n\u001b[1;32m    336\u001b[0m     xp \u001b[38;5;241m=\u001b[39m get_array_namespace(array)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddict_predictors = defaultdict(dict)\n",
    "\n",
    "for key,ds in tqdm(ddict.items()):\n",
    "   \n",
    "    for m,member in tqdm(enumerate(ds.member_id.values)):\n",
    "        ds_mem = ds.sel(member_id=member)\n",
    "        \n",
    "        if key == list(ddict.keys())[0]: #common grid, so only need to generate these grids for the first ds\n",
    "            lat_ranges = np.zeros((len(mlr_coefs.tg),int(grid_size/cmip6_resolution)))\n",
    "            lon_ranges = np.zeros((len(mlr_coefs.tg),int(grid_size/cmip6_resolution)))\n",
    "\n",
    "            for t,tg in enumerate(mlr_coefs.tg.values):\n",
    "                lat_ranges[t,:] = ds_mem.latitude[((ds_mem.latitude>=(mlr_coefs.sel(tg=tg).lat-grid_size/2)) & (ds_mem.latitude<=(mlr_coefs.sel(tg=tg).lat+grid_size/2)))][0:int(grid_size/cmip6_resolution)]\n",
    "                lon_ranges[t,:] = ds_mem.longitude[((ds_mem.longitude>=(mlr_coefs.sel(tg=tg).lon-grid_size/2)) & (ds_mem.longitude<=(mlr_coefs.sel(tg=tg).lon+grid_size/2)))][0:int(grid_size/cmip6_resolution)]\n",
    "        \n",
    "            lons_da = xr.DataArray(lon_ranges,dims=['tg','lon_around_tg'],coords={'tg':mlr_coefs.tg,'lon_around_tg':np.arange(0,int(grid_size/cmip6_resolution))})\n",
    "            lats_da = xr.DataArray(lat_ranges,dims=['tg','lat_around_tg'],coords={'tg':mlr_coefs.tg,'lat_around_tg':np.arange(0,int(grid_size/cmip6_resolution))})\n",
    "        \n",
    "        \n",
    "        #sanity check timeseries length\n",
    "        num_days = (ds_mem.time[-1]-ds_mem.time[0]).dt.days\n",
    "        assert (len(ds_mem.time) > .9*num_days) & (len(ds_mem.time) < 1.1*num_days)\n",
    "        \n",
    "        predictors = ds_mem\n",
    "        \n",
    "        #generate predictors\n",
    "        predictors['sfcWind_sqd'] = predictors['sfcWind']**2 #add wind squared\n",
    "        predictors['sfcWind_cbd'] = predictors['sfcWind']**3 #add wind cubed\n",
    "        \n",
    "        predictors = (predictors-predictors.mean(dim='time'))/predictors.std(dim='time',ddof=0) #normalize predictor variables (ignores nan by default?)\n",
    "        predictors = predictors.sel(latitude=lats_da,longitude=lons_da).load() #takes a lot of memory, but is much more efficient than loading per TG?\n",
    "        \n",
    "        #concatenate & stack normalized forcing variables to data array with shape (time,(4 variables * grid_size * grid_size))\n",
    "        predictors['predictors'] = predictors[[\"psl\", \"sfcWind\", \"sfcWind_sqd\",\"sfcWind_cbd\"]].to_array(dim=\"predictor_var\") \n",
    "        predictors['predictors'] = predictors['predictors'].transpose(\"time\",\"predictor_var\",\"lon_around_tg\",...).stack(f=['predictor_var','lon_around_tg','lat_around_tg'],create_index=False)\n",
    "            \n",
    "        #compute surges from predictors\n",
    "        if m==0: #initialize\n",
    "            surge_ds = xr.Dataset(data_vars=dict(surge=(['member_id','time','tg'], np.nan*np.zeros( (len(ds.member_id),len(ds.time),len(mlr_coefs.tg))) )),\n",
    "                            coords=dict(member_id=ds.member_id,time=ds.time,tg=mlr_coefs.tg)) #initialize output dataset per model\n",
    "        \n",
    "        for t,tg in enumerate(mlr_coefs.tg):\n",
    "            predictors_at_tg = predictors.sel(tg=tg)\n",
    "            mlr_coefs_at_tg = mlr_coefs.mlr_coefs.sel(tg=tg)\n",
    "            \n",
    "            num_pcs = int(np.sum(np.isfinite(mlr_coefs_at_tg)))-1 #number of mlr coefs = number of PCs to derive, intercept doesn't count\n",
    "            idx_timesteps_w_data = np.argwhere((np.isfinite(predictors_at_tg.predictors).all(axis=1)).values).flatten() #omit timesteps with NaN if any\n",
    "            \n",
    "            #get principal components (using sklearn to keep deterministic signs consistent)\n",
    "            pca = PCA(num_pcs)\n",
    "            pca.fit(predictors_at_tg.predictors.isel(time=idx_timesteps_w_data)) #remove missing values for PCA\n",
    "            pcs = pca.transform(predictors_at_tg.predictors.isel(time=idx_timesteps_w_data))\n",
    "            \n",
    "            components = xr.DataArray(data=pca.components_,dims=['pc','f'],coords=dict(pc=np.arange(num_pcs),f=predictors_at_tg.f))\n",
    "            \n",
    "            #compute RMSEs with ERA5 principal components, only considering the pressure part of the forcing (first num_grid_cells**2)\n",
    "            rmses = np.sqrt(((components.isel(f=np.arange(num_grid_cells**2))-era5_pcs.sel(tg=tg).isel(f=np.arange(num_grid_cells**2)).isel(pc=np.arange(num_pcs)).component)**2).mean(dim='f')) #original sign\n",
    "            rmses_flipped = np.sqrt(((components.isel(f=np.arange(num_grid_cells**2))--era5_pcs.isel(f=np.arange(num_grid_cells**2)).sel(tg=tg).isel(pc=np.arange(num_pcs)).component)**2).mean(dim='f')) #opposite sign\n",
    "\n",
    "            s = (rmses<rmses_flipped).astype('int') #flip pcs if rmse of flipped pc is lower\n",
    "            s[s==0]=-1\n",
    "            pcs = pcs * s.values\n",
    "            \n",
    "            #multiply with ERA5 regression coefficients to compute surges\n",
    "            surge_ds['surge'][m,idx_timesteps_w_data,t] = np.sum(mlr_coefs_at_tg[np.isfinite(mlr_coefs_at_tg)].values * np.column_stack((np.ones(pcs.shape[0]),pcs)),axis=1) \n",
    "            \n",
    "    #surge_ds.to_zarr(os.path.join('gs://',output_dir,ds.source_id,key+'.zarr'),mode='w')\n",
    "    #surge_ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
