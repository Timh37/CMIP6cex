{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdc315e-ee78-4daa-90d2-caab58fceb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3036/2320150046.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'script to concatenate historical and ssp runs from different CMIP6 models and members'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import dask\n",
    "import intake\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() # equivalent to fsspec.fs('gs')\n",
    "\n",
    "'''script to concatenate historical and ssp runs from different CMIP6 models and members'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6076a1f3-7194-4f91-bcd8-93dad0674e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'psl' #variable to process\n",
    "domain = 'europe' #europe, tgs\n",
    "\n",
    "in_dir = 'leap-persistent/timh37/CMIP6/subsetted_data/'+variable+'_'+domain+'/' #where to open\n",
    "out_dir = 'leap-persistent/timh37/CMIP6/timeseries/'+variable+'_'+domain+'/' #where to store\n",
    "\n",
    "models = [k.split('/')[-1] for k in fs.ls(in_dir) if k.startswith('.')==False] #find models vor variable\n",
    "\n",
    "ddict = defaultdict(dict) #initialize dictionary to store datasets in\n",
    "\n",
    "for source_id in ['MPI-ESM1-2-HR']:#models:\n",
    "    experiments = [s.split('/')[-1].split('_')[2] for s in fs.ls(os.path.join(in_dir,source_id))] #find experiments available for model\n",
    "    experiment_ids = [s for s in experiments if s.startswith('.')==False]\n",
    "    for experiment_id in set(experiment_ids): #for each experiment_id, open the datasets, concatenating all variants:\n",
    "        source_ds = xr.open_mfdataset(os.path.join('gs://',in_dir,source_id,'*'+experiment_id+'*.zarr'),join='outer',combine='nested',\n",
    "                                      compat='override',coords='minimal',concat_dim='member_id',engine='zarr',chunks={}) #need to test this for large np. of realizations, like EC-Earth3\n",
    "        \n",
    "        ddict[source_ds.original_key.rsplit('.',1)[0]] = source_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e90a3-899e-4843-951e-9d86a7565fb1",
   "metadata": {},
   "source": [
    "Append SSP runs to historical runs for each SSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaec14d0-d43a-449c-9d35-8a268a8f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssps = set([k.split('.')[2] for k in ddict.keys() if 'ssp' in k]) #find unique SSPs in dictionary\n",
    "\n",
    "ddict_concat = defaultdict(dict)\n",
    "\n",
    "for ssp in ssps: #loop over SSPs\n",
    "    ddict_ssp = defaultdict(dict)\n",
    "    \n",
    "    for k in ddict.keys():\n",
    "        if ((ssp in k) or ('historical' in k)):\n",
    "            if k.replace('historical',ssp) in ddict.keys(): #only consider historical if there's also ssp\n",
    "                ddict_ssp[k] = ddict[k]\n",
    "            \n",
    "    #append SSP to historical, only for realizations for which both experiments are provided (join=inner)\n",
    "    hist_ssp = combine_datasets(ddict_ssp,_concat_sorted_time,match_attrs =['source_id', 'grid_label','table_id'],combine_func_kwargs={'join':'inner'})\n",
    "\n",
    "    for key,ds in hist_ssp.items(): #put back together in dictionary\n",
    "        ddict_concat[key+'.'+ssp] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc8510-9ef4-4e00-8d6f-a5793db3d267",
   "metadata": {},
   "source": [
    "Store per SSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696f8bee-abd9-471f-b2ba-8245ea76969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab1c0195a3246cc81d3a4be137141ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key,ds in tqdm(ddict_concat.items()):\n",
    "    model_path = os.path.join(out_dir,ds.source_id)\n",
    "    \n",
    "    if 'tg' in ds.coords:\n",
    "        ds['tg'] = ds.tg.astype('str') #something wrong with encoding object types in zarr, this is the work-around\n",
    "    ds['member_id'] = ds.member_id.astype('str')\n",
    "    \n",
    "    if 'chunks' in ds[variable].encoding: #something wrong with encoding of chunks for saving to zarr, this is the work-around\n",
    "        del ds[variable].encoding['chunks']\n",
    "    \n",
    "    if 'longitude' in ds.coords:    \n",
    "        ds.chunk({'member_id':1,'longitude':5,'time':100000}).to_zarr(os.path.join('gs://',model_path,key.replace('.','_')+'.zarr'),mode='w')\n",
    "    else:\n",
    "        ds.chunk({'member_id':1,'time':100000}).to_zarr(os.path.join('gs://',model_path,key.replace('.','_')+'.zarr'),mode='w')\n",
    "    \n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0511d-368c-4c78-9a07-732cf6b03dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
