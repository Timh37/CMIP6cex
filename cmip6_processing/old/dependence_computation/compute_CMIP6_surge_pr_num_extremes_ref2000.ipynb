{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8899c2-c522-42e0-aa61-ce53a758f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1462/3902141566.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import fnmatch\n",
    "from tqdm.autonotebook import tqdm\n",
    "import dask\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/CMIP6cf/cmip6cf/')\n",
    "\n",
    "from dependence_metrics import kendallstau, utdc_at_threshold, utdc_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853c8e9b-73b2-47c3-9881-09abe4ce60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot(da,threshold,dim):\n",
    "    \n",
    "    assert (threshold>=0) & (threshold<1)\n",
    "    \n",
    "    return da.where(da>da.quantile(threshold,dim=dim))\n",
    "\n",
    "def declustered_peaks(da,threshold,window_len,dim):\n",
    "    #computes peaks above threshold of xr.DataArray and declusters them with a rolling window.\n",
    "    \n",
    "    peaks = pot(da,threshold,dim)\n",
    "    \n",
    "    return peaks.where(peaks==peaks.rolling({dim:window_len},center=True,min_periods=1).max(skipna=True))\n",
    "\n",
    "def rolling_max(da,window_len,dim):\n",
    "    return da.rolling({dim:window_len},center=True,min_periods=1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be0e9a-7d00-4d95-b211-57e51b0467c6",
   "metadata": {},
   "source": [
    "Configure the bivariate sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e2303f-56de-45d6-9f19-0e31cf0af7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 0 #days\n",
    "declus_window_len = 1 #days\n",
    "threshold = .98 #quantile\n",
    "\n",
    "output_yrs = np.arange(1880,2100,20)\n",
    "window_len=40 #may need to increase? indicate settings in output folder?\n",
    "\n",
    "season = 'year' \n",
    "overwrite_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57ca67d-4dd6-4eb7-bd54-d3f2d63df818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CESM2-WACCM_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262427c1a4604778b9b89f2ea36c7271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CESM2-WACCM_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc3b83527f445e7953cfaed9de3917e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CMCC-CM2-SR5_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec4e516f0974cc8bf7a154281844429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CMCC-CM2-SR5_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba4c155df7345b38b806c81cfc4426d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: EC-Earth3_gr_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd381d953576495f8fd05a401d82979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: EC-Earth3_gr_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4569733214d8dad1b918cf596129f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MIROC6_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c300a3affb4f039b21b86e482d5a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MIROC6_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2895a8b9f0f744b5854b3d43b541e96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MRI-ESM2-0_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0331c535cabf49d49e0a02ac1d0fb9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MRI-ESM2-0_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffe51e84eb941db82ede9c487db13b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: GFDL-ESM4_gr1_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e315dfa9ae5c4d9e847e94bea358cd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: GFDL-ESM4_gr1_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26035792d2d34d4cadd3f415524740b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: GFDL-CM4_gr1_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eba82c7cac444eb7cbbddd1dadf234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: GFDL-CM4_gr1_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4452270d2b6043d6b927ee66d9b53ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: NorESM2-MM_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0865d308fc7646bba43b924fcf1d4a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: NorESM2-MM_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b04ddb2b3b454e9c12e7a461f9f062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MPI-ESM1-2-HR_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b3fac0dcf4fc4a8464c9c0051671c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MPI-ESM1-2-HR_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a38bb57335a4d73bb7e06a36e61eb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: TaiESM1_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225ccb27a18f44498130d3d055522ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: TaiESM1_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0f99bf9cc443c1b22d91dbfbd48de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: HadGEM3-GC31-MM_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c85454156b4a74a17b112b48ab4878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CESM2_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb1e99adddc40ff92c5b76968b4bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CESM2_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbbfcf41b974d499f38f3a26dab6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CMCC-ESM2_gn_day_ssp585.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8512b5ac7c5497db29d9e80d0514868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CMCC-ESM2_gn_day_ssp245.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90fe8e393a4cda9e47cba9be6790e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sfcWind_dir = '/home/jovyan/CMIP6cf/output/timeseries/sfcWind_tgs'\n",
    "pr_dir = '/home/jovyan/CMIP6cf/output/timeseries/pr_tgs'\n",
    "\n",
    "source_ids = list(set(os.listdir(sfcWind_dir)) & set(os.listdir(pr_dir))) #intersection of models\n",
    "\n",
    "for source_id in [k for k in source_ids if ~k.startswith('.')]: #loop over models\n",
    "  \n",
    "    sfcWind_path = os.path.join(sfcWind_dir,source_id)\n",
    "    pr_path = os.path.join(pr_dir,source_id)\n",
    "    \n",
    "    sfcWind_exps = [s.split('_')[-1][0:-3] for s in os.listdir(sfcWind_path) if s.startswith('.')==False]\n",
    "    pr_exps = [s.split('_')[-1][0:-3] for s in os.listdir(pr_path) if s.startswith('.')==False]\n",
    "    \n",
    "    experiment_ids = list(set(sfcWind_exps) & set(pr_exps))\n",
    "\n",
    "    for experiment_id in experiment_ids: #loop over experiments\n",
    "        #load data\n",
    "        fn = fnmatch.filter(os.listdir(sfcWind_path),'*'+experiment_id+'*')[0]\n",
    "        print('Processing file: '+fn)\n",
    "    \n",
    "        sfcWind_pr = xr.open_mfdataset((os.path.join(sfcWind_path,fn),os.path.join(pr_path,fn)),chunks={'member_id':1,'time':100000,'tg':109})#.sel(longitude=np.arange(-25,11))\n",
    "        \n",
    "        #generate output paths & check if output already exists\n",
    "        #model_path = os.path.join('/home/jovyan/CMIP6cf/output/dependence/sfcWind_pr_europe/40yr_p98_lag0d_declus1d_ref2000',sfcWind_pr.source_id)\n",
    "        model_path = os.path.join('/home/jovyan/CMIP6cf/output/dependence/sfcWind_pr_tgs/40yr_p98_lag0d_declus1d_ref2000',sfcWind_pr.source_id)\n",
    "        output_fn = os.path.join(model_path,fn)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            os.mkdir(model_path)\n",
    "\n",
    "        if not overwrite_output: #if not overwriting existing output\n",
    "            if os.path.exists(output_fn):\n",
    "                print('Output already exists for this instance.')\n",
    "                continue\n",
    "        \n",
    "        #construct time window indices\n",
    "        if len(np.unique(sfcWind_pr.time.resample(time='1Y').count()))>1: #remove leap days so that each computation window has the same length\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "                sfcWind_pr = sfcWind_pr.sel(time=~((sfcWind_pr.time.dt.month == 2) & (sfcWind_pr.time.dt.day == 29))) #^probably (hopefully) only has a small effect on the results\n",
    "        \n",
    "        #select DJF:\n",
    "        days_in_year = int(sfcWind_pr.time.resample(time='1Y').count()[0])\n",
    "        \n",
    "        if window_len%2 !=0: #odd\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(np.floor(window_len/2)))\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        else: #even\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(window_len/2)+1)\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        \n",
    "        if np.max(first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:])>=len(sfcWind_pr.time):\n",
    "            raise Exception('Windows exceed simulation length.')\n",
    "            \n",
    "        window_idx = xr.DataArray( #indices of windows\n",
    "            data=first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:],\n",
    "            dims=[\"time_in_window_idx\",\"window\"],\n",
    "            coords=dict(\n",
    "                time_in_window_idx=first_window_idx,\n",
    "                window=output_yrs\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        for m,member in tqdm(enumerate(sfcWind_pr.member_id)): #loop over members to compute the dependence\n",
    "        \n",
    "            sfcWind_pr_mem = sfcWind_pr.sel(member_id=member)#.copy(deep=True)\n",
    "            \n",
    "            sfcWind_pr_wdws = sfcWind_pr_mem.isel(time=window_idx) #select windows\n",
    "   \n",
    "            data_is_complete = np.isfinite(sfcWind_pr_wdws.sfcWind).all(dim='time_in_window_idx') * np.isfinite(sfcWind_pr_wdws.pr).all(dim='time_in_window_idx')\n",
    "        \n",
    "            pr_hist_threshold = sfcWind_pr_wdws['pr'].sel(window=2000).quantile(threshold,dim='time_in_window_idx')\n",
    "            sfcWind_hist_threshold = sfcWind_pr_wdws['sfcWind'].sel(window=2000).quantile(threshold,dim='time_in_window_idx')\n",
    "\n",
    "            pr_peaks = sfcWind_pr_wdws['pr'].where(sfcWind_pr_wdws['pr']>pr_hist_threshold)\n",
    "            sfcWind_peaks = sfcWind_pr_wdws['sfcWind'].where(sfcWind_pr_wdws['sfcWind']>sfcWind_hist_threshold)\n",
    "            \n",
    "            pr_peaks_declustered = pr_peaks.where(pr_peaks==pr_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            sfcWind_peaks_declustered = sfcWind_peaks.where(sfcWind_peaks==sfcWind_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            \n",
    "            #decomposition (only works for declustering = 0 and lag =1)?\n",
    "            \n",
    "            #sort values in historical period\n",
    "            #europe:\n",
    "            sorted_pr_2000 = xr.DataArray(data=np.sort(sfcWind_pr_wdws.sel(window=2000).pr,axis=0),dims=['time_in_window_idx','tg'],\n",
    "                                          coords=dict(time_in_window_idx=sfcWind_pr_wdws.time_in_window_idx,tg=sfcWind_pr_wdws.tg))\n",
    "            sorted_sfcWind_2000 = xr.DataArray(data=np.sort(sfcWind_pr_wdws.sel(window=2000).sfcWind,axis=0),dims=['time_in_window_idx','tg'],\n",
    "                                               coords=dict(time_in_window_idx=sfcWind_pr_wdws.time_in_window_idx,tg=sfcWind_pr_wdws.tg))\n",
    "\n",
    "            #tgs:\n",
    "            \n",
    "            \n",
    "            #derive percentile values based on number of exceedences of historical 98% in the future & determine peaks, #potentially expand this to other windows than just 2080\n",
    "            pr_eqv_thresholds = sorted_pr_2000.isel(time_in_window_idx=-1*(np.isfinite(pr_peaks_declustered).sum(dim='time_in_window_idx').sel(window=2080).load()))\n",
    "            wind_eqv_thresholds = sorted_sfcWind_2000.isel(time_in_window_idx=-1*(np.isfinite(sfcWind_peaks_declustered).sum(dim='time_in_window_idx').sel(window=2080).load()))\n",
    "            \n",
    "            pr_peaks_fut_threshold = sfcWind_pr_wdws.pr.sel(window=2000).where(sfcWind_pr_wdws.pr.sel(window=2000)>=pr_eqv_thresholds)\n",
    "            sfcWind_peaks_fut_threshold = sfcWind_pr_wdws.sfcWind.sel(window=2000).where(sfcWind_pr_wdws.sfcWind.sel(window=2000)>=wind_eqv_thresholds)\n",
    "\n",
    "            #compute number of co_occurring extremes due to different effects\n",
    "\n",
    "            #co occurring pr fut threshold\n",
    "            num_co_occurring_pr_driven = np.isfinite((rolling_max(pr_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_declustered.sel(window=2000))).sum(dim='time_in_window_idx')\n",
    "\n",
    "            #co occurring wind fut threshold \n",
    "            num_co_occurring_wind_driven = np.isfinite((rolling_max(pr_peaks_declustered.sel(window=2000),max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_fut_threshold)).sum(dim='time_in_window_idx')\n",
    "\n",
    "            #co occurring both new threshold\n",
    "            num_co_occurring_both_driven = np.isfinite((rolling_max(pr_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_fut_threshold)).sum(dim='time_in_window_idx')\n",
    "           \n",
    "            \n",
    "            #pr_peaks_declustered = declustered_peaks(sfcWind_pr_wdws['pr'],threshold,declus_window_len,dim='time_in_window_idx')\n",
    "            #sfcWind_peaks_declustered = declustered_peaks(sfcWind_pr_wdws['sfcWind'],threshold,declus_window_len,dim='time_in_window_idx')\n",
    "            \n",
    "            #count occurrences of peaks\n",
    "            co_occurring = np.isfinite((rolling_max(pr_peaks_declustered,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_declustered))\n",
    "            \n",
    "            for month in np.arange(1,13):\n",
    "                if month==1:\n",
    "                    num_co_occurring_pmonth = co_occurring.where(co_occurring.time.dt.month==month).sum(dim='time_in_window_idx')\n",
    "                    num_pr_peaks_pmonth = np.isfinite(pr_peaks_declustered.where(pr_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')\n",
    "                    num_sfcWind_peaks_pmonth = np.isfinite(sfcWind_peaks_declustered.where(sfcWind_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')\n",
    "                else:\n",
    "                    num_co_occurring_pmonth = xr.concat((num_co_occurring_pmonth,co_occurring.where(co_occurring.time.dt.month==month).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    num_pr_peaks_pmonth = xr.concat((num_pr_peaks_pmonth,np.isfinite(pr_peaks_declustered.where(pr_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    num_sfcWind_peaks_pmonth = xr.concat((num_sfcWind_peaks_pmonth,np.isfinite(sfcWind_peaks_declustered.where(sfcWind_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    \n",
    "            num_co_occurring_pmonth = num_co_occurring_pmonth.assign_coords({'month':np.arange(1,13)})                             \n",
    "            num_pr_peaks_pmonth = num_pr_peaks_pmonth.assign_coords({'month':np.arange(1,13)})       \n",
    "            num_sfcWind_peaks_pmonth = num_sfcWind_peaks_pmonth.assign_coords({'month':np.arange(1,13)})       \n",
    "            \n",
    "            #dependence_mem = xr.concat([ktau_pr_cdon_sfcWind,ktau_sfcWind_cdon_pr,ktau_both_peaks],dim='extreme_variate').to_dataset(name='ktau')\n",
    "                \n",
    "            dependence_mem = num_co_occurring_pmonth.to_dataset(name='num_co_occurring')\n",
    "            dependence_mem['num_pr_peaks'] = num_pr_peaks_pmonth\n",
    "            dependence_mem['num_sfcWind_peaks'] = num_sfcWind_peaks_pmonth\n",
    "           \n",
    "            dependence_mem['num_co_occurring_pr_driven']   = num_co_occurring_pr_driven\n",
    "            dependence_mem['num_co_occurring_sfcWind_driven'] = num_co_occurring_wind_driven\n",
    "            dependence_mem['num_co_occurring_both_driven'] = num_co_occurring_both_driven\n",
    "            \n",
    "            dependence_mem['num_co_occurring_pr_driven'].attrs['window']='2061-2100'\n",
    "            dependence_mem['num_co_occurring_sfcWind_driven'].attrs['window']='2061-2100'\n",
    "            dependence_mem['num_co_occurring_both_driven'].attrs['window']='2061-2100'\n",
    "           \n",
    "            #store thresholds\n",
    "            dependence_mem['sfcWind_thresholds_annual'] = sfcWind_pr_wdws['sfcWind'].quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_annual'] = sfcWind_pr_wdws['pr'].quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_djf'] = sfcWind_pr_wdws['sfcWind'].where(np.mod(sfcWind_pr_wdws.time.dt.month,12)<3).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_djf'] = sfcWind_pr_wdws['pr'].where(np.mod(sfcWind_pr_wdws.time.dt.month,12)<3).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_mam'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>2) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<6)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_mam'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>2) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<6)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_jja'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>5) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<9)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_jja'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>5) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<9)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_son'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>8) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<12)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_son'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>8) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<12)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['complete_window'] = data_is_complete #store where windows miss data\n",
    "            \n",
    "            \n",
    "            dependence_mem = dependence_mem.expand_dims(dim={\"member_id\": 1}) #add coordinates & dimensions\n",
    "            #dependence_mem = dependence_mem.assign_coords({'extreme_variate':['sfcWind','pr','both'],'statistic':['coef','p'],'estimator':['cfg','.95']})\n",
    "            '''\n",
    "            if m==0: #concatenate results over member_id's\n",
    "                dependence = dependence_mem\n",
    "            else:\n",
    "                dependence = xr.concat((dependence,dependence_mem),dim='member_id')    \n",
    "            '''\n",
    "            dependence_mem.attrs = sfcWind_pr.attrs #keep original attributes and add information on the extremes analysis\n",
    "            dependence_mem.attrs['window_length'] = str(window_len)\n",
    "            dependence_mem.attrs['declustering'] = 'Rolling window of '+str(declus_window_len)+' days'\n",
    "            dependence_mem.attrs['allowed_lag'] = str(max_lag)\n",
    "\n",
    "            dependence_mem.to_netcdf(output_fn[0:-3]+'_'+dependence_mem.member_id.values[0]+'.nc',mode='w')\n",
    "            dependence_mem.close()\n",
    "        '''    \n",
    "        dependence.attrs = sfcWind_pr.attrs #keep original attributes and add information on the extremes analysis\n",
    "        dependence.attrs['window_length'] = str(window_len)\n",
    "        dependence.attrs['declustering'] = 'Rolling window of '+str(declus_window_len)+' days'\n",
    "        dependence.attrs['allowed_lag'] = str(max_lag)\n",
    "\n",
    "        dependence.to_netcdf(output_fn,mode='w')\n",
    "        dependence.close()\n",
    "        '''\n",
    "        #store for all members of this model & experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e280ae4-a2b1-4352-8c55-4c8e964d24f7",
   "metadata": {},
   "source": [
    "```\n",
    "sfcWind_dir = '/home/jovyan/CMIP6cf/output/timeseries/sfcWind_europe/'\n",
    "pr_dir = '/home/jovyan/CMIP6cf/output/timeseries/pr_europe/'\n",
    "\n",
    "source_ids = list(set(os.listdir(sfcWind_dir)) & set(os.listdir(pr_dir))) #intersection of models\n",
    "\n",
    "for source_id in ['EC-Earth3']:#[k for k in source_ids if ~k.startswith('.')]: #loop over models\n",
    "  \n",
    "    sfcWind_path = os.path.join(sfcWind_dir,source_id)\n",
    "    pr_path = os.path.join(pr_dir,source_id)\n",
    "    \n",
    "    sfcWind_exps = [s.split('_')[-1][0:-3] for s in os.listdir(sfcWind_path) if s.startswith('.')==False]\n",
    "    pr_exps = [s.split('_')[-1][0:-3] for s in os.listdir(pr_path) if s.startswith('.')==False]\n",
    "    \n",
    "    experiment_ids = list(set(sfcWind_exps) & set(pr_exps))\n",
    "\n",
    "    for experiment_id in experiment_ids: #loop over experiments\n",
    "        #load data\n",
    "        fn = fnmatch.filter(os.listdir(sfcWind_path),'*'+experiment_id+'*')[0]\n",
    "        print('Processing file: '+fn)\n",
    "        sfcWind_pr = xr.open_mfdataset((os.path.join(sfcWind_path,fn),os.path.join(pr_path,fn)),chunks={'member_id':1,'time':100000,'longitude':5})#.sel(longitude=np.arange(-25,11))\n",
    "        \n",
    "        #generate output paths & check if output already exists\n",
    "        model_path = os.path.join('/home/jovyan/CMIP6cf/output/dependence/sfcWind_pr_europe/40yr_p98_lag0d_declus1d_ref1980',sfcWind_pr.source_id)\n",
    "        output_fn = os.path.join(model_path,fn)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            os.mkdir(model_path)\n",
    "\n",
    "        if not overwrite_output: #if not overwriting existing output\n",
    "            if os.path.exists(output_fn):\n",
    "                print('Output already exists for this instance.')\n",
    "                continue\n",
    "        \n",
    "        #construct time window indices\n",
    "        if len(np.unique(sfcWind_pr.time.resample(time='1Y').count()))>1: #remove leap days so that each computation window has the same length\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "                sfcWind_pr = sfcWind_pr.sel(time=~((sfcWind_pr.time.dt.month == 2) & (sfcWind_pr.time.dt.day == 29))) #^probably (hopefully) only has a small effect on the results\n",
    "        \n",
    "        #select DJF:\n",
    "        days_in_year = int(sfcWind_pr.time.resample(time='1Y').count()[0])\n",
    "        \n",
    "        if window_len%2 !=0: #odd\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(np.floor(window_len/2)))\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        else: #even\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(window_len/2)+1)\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        \n",
    "        if np.max(first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:])>=len(sfcWind_pr.time):\n",
    "            raise Exception('Windows exceed simulation length.')\n",
    "            \n",
    "        window_idx = xr.DataArray( #indices of windows\n",
    "            data=first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:],\n",
    "            dims=[\"time_in_window_idx\",\"window\"],\n",
    "            coords=dict(\n",
    "                time_in_window_idx=first_window_idx,\n",
    "                window=output_yrs\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        for m,member in tqdm(enumerate(sfcWind_pr.member_id)): #loop over members to compute the dependence\n",
    "            sfcWind_pr_mem = sfcWind_pr.sel(member_id=member).copy(deep=True).load()\n",
    "            \n",
    "            sfcWind_pr_wdws = sfcWind_pr_mem.isel(time=window_idx) #select windows\n",
    "   \n",
    "            data_is_complete = np.isfinite(sfcWind_pr_wdws.sfcWind).all(dim='time_in_window_idx') * np.isfinite(sfcWind_pr_wdws.pr).all(dim='time_in_window_idx')\n",
    "            \n",
    "            pr_hist_threshold = sfcWind_pr_wdws['pr'].sel(window=1980).quantile(threshold,dim='time_in_window_idx')\n",
    "            sfcWind_hist_threshold = sfcWind_pr_wdws['sfcWind'].sel(window=1980).quantile(threshold,dim='time_in_window_idx')\n",
    "\n",
    "            pr_peaks = sfcWind_pr_wdws['pr'].where(sfcWind_pr_wdws['pr']>pr_hist_threshold)\n",
    "            sfcWind_peaks = sfcWind_pr_wdws['sfcWind'].where(sfcWind_pr_wdws['sfcWind']>sfcWind_hist_threshold)\n",
    "            \n",
    "            pr_peaks_declustered = pr_peaks.where(pr_peaks==pr_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            sfcWind_peaks_declustered = sfcWind_peaks.where(sfcWind_peaks==sfcWind_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            \n",
    "            #decomposition (only works for declustering = 0 and lag =1)?\n",
    "            \n",
    "            #sort values in historical period\n",
    "         \n",
    "            sorted_pr_1980 = xr.DataArray(data=np.sort(sfcWind_pr_wdws.sel(window=1980).pr,axis=0),dims=['time_in_window_idx','latitude','longitude'],\n",
    "                                          coords=dict(time_in_window_idx=sfcWind_pr_wdws.time_in_window_idx,latitude=sfcWind_pr_wdws.latitude,longitude=sfcWind_pr_wdws.longitude)).chunk({'longitude':5})\n",
    "            sorted_sfcWind_1980 = xr.DataArray(data=np.sort(sfcWind_pr_wdws.sel(window=1980).sfcWind,axis=0),dims=['time_in_window_idx','latitude','longitude'],\n",
    "                                               coords=dict(time_in_window_idx=sfcWind_pr_wdws.time_in_window_idx,latitude=sfcWind_pr_wdws.latitude,longitude=sfcWind_pr_wdws.longitude)).chunk({'longitude':5})\n",
    "\n",
    "            #derive percentile values based on number of exceedences of historical 98% in the future & determine peaks, #potentially expand this to other windows than just 2080\n",
    "            pr_eqv_thresholds = sorted_pr_1980.isel(time_in_window_idx=-1*(np.isfinite(pr_peaks_declustered).sum(dim='time_in_window_idx').sel(window=2080).load()))\n",
    "            wind_eqv_thresholds = sorted_sfcWind_1980.isel(time_in_window_idx=-1*(np.isfinite(sfcWind_peaks_declustered).sum(dim='time_in_window_idx').sel(window=2080).load()))\n",
    "            \n",
    "            pr_peaks_fut_threshold = sfcWind_pr_wdws.pr.sel(window=1980).where(sfcWind_pr_wdws.pr.sel(window=1980)>=pr_eqv_thresholds)\n",
    "            sfcWind_peaks_fut_threshold = sfcWind_pr_wdws.sfcWind.sel(window=1980).where(sfcWind_pr_wdws.sfcWind.sel(window=1980)>=wind_eqv_thresholds)\n",
    "\n",
    "            #compute number of co_occurring extremes due to different effects\n",
    "\n",
    "            #co occurring pr fut threshold\n",
    "            num_co_occurring_pr_driven = np.isfinite((rolling_max(pr_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_declustered.sel(window=1980))).sum(dim='time_in_window_idx')\n",
    "\n",
    "            #co occurring wind fut threshold \n",
    "            num_co_occurring_wind_driven = np.isfinite((rolling_max(pr_peaks_declustered.sel(window=1980),max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_fut_threshold)).sum(dim='time_in_window_idx')\n",
    "\n",
    "            #co occurring both new threshold\n",
    "            num_co_occurring_both_driven = np.isfinite((rolling_max(pr_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_fut_threshold)).sum(dim='time_in_window_idx')\n",
    "           \n",
    "            \n",
    "            #pr_peaks_declustered = declustered_peaks(sfcWind_pr_wdws['pr'],threshold,declus_window_len,dim='time_in_window_idx')\n",
    "            #sfcWind_peaks_declustered = declustered_peaks(sfcWind_pr_wdws['sfcWind'],threshold,declus_window_len,dim='time_in_window_idx')\n",
    "            \n",
    "            #count occurrences of peaks\n",
    "            co_occurring = np.isfinite((rolling_max(pr_peaks_declustered,max_lag*2+1,dim='time_in_window_idx')*sfcWind_peaks_declustered))\n",
    "            \n",
    "            for month in np.arange(1,13):\n",
    "                if month==1:\n",
    "                    num_co_occurring_pmonth = co_occurring.where(co_occurring.time.dt.month==month).sum(dim='time_in_window_idx')\n",
    "                    num_pr_peaks_pmonth = np.isfinite(pr_peaks_declustered.where(pr_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')\n",
    "                    num_sfcWind_peaks_pmonth = np.isfinite(sfcWind_peaks_declustered.where(sfcWind_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')\n",
    "                else:\n",
    "                    num_co_occurring_pmonth = xr.concat((num_co_occurring_pmonth,co_occurring.where(co_occurring.time.dt.month==month).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    num_pr_peaks_pmonth = xr.concat((num_pr_peaks_pmonth,np.isfinite(pr_peaks_declustered.where(pr_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    num_sfcWind_peaks_pmonth = xr.concat((num_sfcWind_peaks_pmonth,np.isfinite(sfcWind_peaks_declustered.where(sfcWind_peaks_declustered.time.dt.month==month)).sum(dim='time_in_window_idx')),dim='month')\n",
    "                    \n",
    "            num_co_occurring_pmonth = num_co_occurring_pmonth.assign_coords({'month':np.arange(1,13)})                             \n",
    "            num_pr_peaks_pmonth = num_pr_peaks_pmonth.assign_coords({'month':np.arange(1,13)})       \n",
    "            num_sfcWind_peaks_pmonth = num_sfcWind_peaks_pmonth.assign_coords({'month':np.arange(1,13)})       \n",
    "            \n",
    "            #dependence_mem = xr.concat([ktau_pr_cdon_sfcWind,ktau_sfcWind_cdon_pr,ktau_both_peaks],dim='extreme_variate').to_dataset(name='ktau')\n",
    "                \n",
    "            dependence_mem = num_co_occurring_pmonth.to_dataset(name='num_co_occurring')\n",
    "            dependence_mem['num_pr_peaks'] = num_pr_peaks_pmonth\n",
    "            dependence_mem['num_sfcWind_peaks'] = num_sfcWind_peaks_pmonth\n",
    "           \n",
    "            dependence_mem['num_co_occurring_pr_driven']   = num_co_occurring_pr_driven\n",
    "            dependence_mem['num_co_occurring_sfcWind_driven'] = num_co_occurring_wind_driven\n",
    "            dependence_mem['num_co_occurring_both_driven'] = num_co_occurring_both_driven\n",
    "            \n",
    "            dependence_mem['num_co_occurring_pr_driven'].attrs['window']='2061-2100'\n",
    "            dependence_mem['num_co_occurring_sfcWind_driven'].attrs['window']='2061-2100'\n",
    "            dependence_mem['num_co_occurring_both_driven'].attrs['window']='2061-2100'\n",
    "           \n",
    "            #store thresholds\n",
    "            dependence_mem['sfcWind_thresholds_annual'] = sfcWind_pr_wdws['sfcWind'].quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_annual'] = sfcWind_pr_wdws['pr'].quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_djf'] = sfcWind_pr_wdws['sfcWind'].where(np.mod(sfcWind_pr_wdws.time.dt.month,12)<3).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_djf'] = sfcWind_pr_wdws['pr'].where(np.mod(sfcWind_pr_wdws.time.dt.month,12)<3).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_mam'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>2) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<6)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_mam'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>2) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<6)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_jja'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>5) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<9)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_jja'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>5) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<9)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            \n",
    "            dependence_mem['sfcWind_thresholds_son'] = sfcWind_pr_wdws['sfcWind'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>8) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<12)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['pr_thresholds_son'] = sfcWind_pr_wdws['pr'].where((np.mod(sfcWind_pr_wdws.time.dt.month,12)>8) & (np.mod(sfcWind_pr_wdws.time.dt.month,12)<12)).quantile(np.arange(.9,1,.01),dim='time_in_window_idx')\n",
    "            dependence_mem['complete_window'] = data_is_complete #store where windows miss data\n",
    "            \n",
    "            \n",
    "            dependence_mem = dependence_mem.expand_dims(dim={\"member_id\": 1}) #add coordinates & dimensions\n",
    "            #dependence_mem = dependence_mem.assign_coords({'extreme_variate':['sfcWind','pr','both'],'statistic':['coef','p'],'estimator':['cfg','.95']})\n",
    "            \n",
    "            if m==0: #concatenate results over member_id's\n",
    "                dependence = dependence_mem\n",
    "            else:\n",
    "                dependence = xr.concat((dependence,dependence_mem),dim='member_id')    \n",
    "            \n",
    "            dependence.attrs = sfcWind_pr.attrs #keep original attributes and add information on the extremes analysis\n",
    "            dependence.attrs['window_length'] = str(window_len)\n",
    "            dependence.attrs['declustering'] = 'Rolling window of '+str(declus_window_len)+' days'\n",
    "            dependence.attrs['allowed_lag'] = str(max_lag)\n",
    "            \n",
    "            #store for all members of this model & experiment\n",
    "            dependence.to_netcdf(output_fn,mode='w')\n",
    "            dependence.close()\n",
    "            ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7006733-c520-4bdf-90a3-baf570401bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
