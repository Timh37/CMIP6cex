{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0ff811-96d3-4c4b-ae9c-5c34ea682794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072/1491363843.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import dask\n",
    "import intake\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.postprocessing import combine_datasets, _match_datasets,_concat_sorted_time\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() #list stores, stripp zarr from filename, load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0790c4-8c30-4d6d-a968-d6c1c2832687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_cat_to_max_num_realizations(cmip6_cat):\n",
    "    '''Reduce grid labels in pangeo cmip6 catalogue by \n",
    "    keeping grid_label and 'ipf' identifier combination with most datasets (=most realizations if using require_all_on)'''\n",
    "    df = cmip6_cat.df\n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    df['ipf'] = [s[s.find('i'):] for s in df.member_id] #extract 'ipf' from 'ripf'\n",
    "\n",
    "    #generate list of tuples of (source_id,ipf,grid_label) that provide most realizations (note this will omit realizations not available at this grid but possibly at others)\n",
    "    max_num_ds_tuples = df.groupby(['source_id','ipf'])['grid_label'].value_counts().groupby(level=0).head(1).index.to_list() #head(1) gives (first) max. value since value_counts sorts max to min\n",
    "    df_filter = pd.DataFrame(max_num_ds_tuples,columns=['source_id','ipf','grid_label']) #generate df to merge catalogue df on\n",
    "    \n",
    "    df = df_filter.merge(right=df, on = ['source_id','ipf','grid_label'], how='left') #do the subsetting\n",
    "    df = df.drop(columns=['ipf']) #clean up\n",
    "    df= df[cols]\n",
    "\n",
    "    cmip6_cat.esmcat._df = df #(columns now ordered differently, probably not an issue?)\n",
    "    return cmip6_cat\n",
    "\n",
    "def drop_vars_from_cat(cmip6_cat,vars_to_drop):\n",
    "    cmip6_cat.esmcat._df = cmip6_cat.df.drop(cmip6_cat.df[cmip6_cat.df.variable_id.isin(vars_to_drop)].index).reset_index(drop=True)\n",
    "    return cmip6_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275aec62-ab17-43c9-bea6-ba3917c6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preselect_years(ddict_in,start_year,end_year):\n",
    "    '''select range of years of datasets'''\n",
    "    ddict_out = defaultdict(dict)\n",
    "    \n",
    "    assert start_year<end_year\n",
    "        \n",
    "    if start_year>2014: #only using SSP\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'ssp' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), str(end_year)))\n",
    "                \n",
    "    elif end_year<=2014: #only using historical\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'historical' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), str(end_year)))\n",
    "                \n",
    "    elif ((start_year<=2014) & (end_year>2014)): #using both\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'ssp' in k:\n",
    "                ddict_out[k] = v.sel(time=slice('2015', str(end_year)))\n",
    "            elif 'historical' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), '2014'))\n",
    "    return ddict_out #NB: may result in no timesteps being selected at all\n",
    "\n",
    "def drop_duplicate_timesteps(ddict_in):\n",
    "    ddict_out = ddict_in\n",
    "    for k, v in ddict_in.items():  \n",
    "        unique_time, idx = np.unique(v.time,return_index=True)\n",
    "        \n",
    "        if len(v.time) != len(unique_time):\n",
    "            ddict_out[k] = v.isel(time=idx)\n",
    "            print('Dropping duplicate timesteps for:' + k)   \n",
    "    return ddict_out\n",
    "\n",
    "def drop_coords(ddict_in,coords_to_drop):\n",
    "    for k, v in ddict_in.items():\n",
    "        ddict_in[k] = v.drop_dims(coords_to_drop,errors=\"ignore\")\n",
    "    return ddict_in\n",
    "\n",
    "def align_lonlat(ds_list):\n",
    "    aligned_ds_list = []\n",
    "    for ds in ds_list: #list of ds can't seem to be passed to xr.align instead\n",
    "        a,b = xr.align(ds_list[0],ds,join='override',exclude=['time','member_id'])\n",
    "        aligned_ds_list.append(b)\n",
    "    return aligned_ds_list\n",
    "\n",
    "def concat_members_aligning_lonlat(ds_list):\n",
    "    aligned_ds_list = align_lonlat(ds_list) #override same-dimension lon/lat prior to concatenating (ensures lon/lats are not padded)\n",
    "    return xr.concat(aligned_ds_list, dim='member_id', join='outer', coords='minimal',compat='override') #return xr.concat(ds_pick, dim='member_id')\n",
    "\n",
    "def merge_variables_aligning_lonlat(ds_list):\n",
    "    aligned_ds_list = align_lonlat(ds_list) #override same-dimension lon/lat prior to concatenating (ensures lon/lats are not padded)\n",
    "    return xr.merge(aligned_ds_list, join='outer',compat='override')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cd8f8-4221-4661-93c7-3652b3c6acc5",
   "metadata": {},
   "source": [
    "Query runs & manipulate catalogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4d6c24-cedc-439a-b12c-30110aaaa899",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','CMCC-ESM2','CMCC-CM2-SR5',\n",
    "                'GFDL-CM4','GFDL-ESM4','HadGEM3-GC31-MM','MIROC6','MPI-ESM1-2-HR','MRI-ESM2-0',\n",
    "                'NorESM2-MM','TaiESM1']\n",
    "'''\n",
    "my_models = ['CESM2','CESM2-WACCM']\n",
    "'''\n",
    "col = google_cmip_col()\n",
    "\n",
    "cat_data_ssp245 = col.search( #find instances providing all required variables for both historical & ssp245\n",
    "    source_id=my_models,\n",
    "    experiment_id=['historical','ssp245'],\n",
    "    table_id='day',\n",
    "    variable_id=['sfcWind','psl','pr'],\n",
    "    require_all_on=['source_id', 'member_id','grid_label']\n",
    ")\n",
    "\n",
    "\n",
    "cat_data_ssp585 = col.search( #find instances providing all required variables for both historical & ssp585\n",
    "    source_id=my_models,\n",
    "    experiment_id=['historical','ssp585'],\n",
    "    table_id='day',\n",
    "    variable_id=['sfcWind','psl','pr'],\n",
    "    require_all_on=['source_id', 'member_id','grid_label']\n",
    ")\n",
    "cat_data = cat_data_ssp585\n",
    "cat_data.esmcat._df = pd.concat([cat_data_ssp245.df,cat_data_ssp585.df],ignore_index=True).drop_duplicates(ignore_index=True) #all instances we want\n",
    "\n",
    "cat_data = reduce_cat_to_max_num_realizations(cat_data) #per model, select grid and 'ipf' combination providing most realizations\n",
    "cat_data = drop_vars_from_cat(cat_data,['pr']) #we query only instances that also provide 'pr', but don't process 'pr' it in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc61fdf-1ec5-4f99-8cc3-a7bb1267d8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/NCAR/CESM2/ssp245...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/NCAR/CESM2/ssp245...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r4i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>historical</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/CMIP/AS-RCEC/TaiESM1/historic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     activity_id institution_id source_id experiment_id  member_id table_id  \\\n",
       "0           CMIP           NCAR     CESM2    historical  r11i1p1f1      day   \n",
       "1           CMIP           NCAR     CESM2    historical  r11i1p1f1      day   \n",
       "2    ScenarioMIP           NCAR     CESM2        ssp245  r11i1p1f1      day   \n",
       "3    ScenarioMIP           NCAR     CESM2        ssp245  r11i1p1f1      day   \n",
       "4           CMIP           NCAR     CESM2    historical   r4i1p1f1      day   \n",
       "..           ...            ...       ...           ...        ...      ...   \n",
       "101         CMIP        AS-RCEC   TaiESM1    historical   r1i1p1f1      day   \n",
       "102  ScenarioMIP        AS-RCEC   TaiESM1        ssp245   r1i1p1f1      day   \n",
       "103  ScenarioMIP        AS-RCEC   TaiESM1        ssp245   r1i1p1f1      day   \n",
       "104  ScenarioMIP        AS-RCEC   TaiESM1        ssp585   r1i1p1f1      day   \n",
       "105  ScenarioMIP        AS-RCEC   TaiESM1        ssp585   r1i1p1f1      day   \n",
       "\n",
       "    variable_id grid_label                                             zstore  \\\n",
       "0           psl         gn  gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r1...   \n",
       "1       sfcWind         gn  gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r1...   \n",
       "2           psl         gn  gs://cmip6/CMIP6/ScenarioMIP/NCAR/CESM2/ssp245...   \n",
       "3       sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/NCAR/CESM2/ssp245...   \n",
       "4       sfcWind         gn  gs://cmip6/CMIP6/CMIP/NCAR/CESM2/historical/r4...   \n",
       "..          ...        ...                                                ...   \n",
       "101     sfcWind         gn  gs://cmip6/CMIP6/CMIP/AS-RCEC/TaiESM1/historic...   \n",
       "102         psl         gn  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...   \n",
       "103     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...   \n",
       "104     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...   \n",
       "105         psl         gn  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...   \n",
       "\n",
       "     dcpp_init_year   version  \n",
       "0               NaN  20190514  \n",
       "1               NaN  20190514  \n",
       "2               NaN  20200528  \n",
       "3               NaN  20200528  \n",
       "4               NaN  20190308  \n",
       "..              ...       ...  \n",
       "101             NaN  20200626  \n",
       "102             NaN  20210222  \n",
       "103             NaN  20210222  \n",
       "104             NaN  20200902  \n",
       "105             NaN  20200902  \n",
       "\n",
       "[106 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166c944-8163-4fa0-9641-1fe8b0f0ec2d",
   "metadata": {},
   "source": [
    "Open datasets into dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d7d0f5-b789-4ad3-ad23-1e0a233e89d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072/772692342.py:12: DeprecationWarning: cdf_kwargs and zarr_kwargs are deprecated and will be removed in a future version. Please use xarray_open_kwargs instead.\n",
      "  ddict = cat_data.to_dataset_dict(**kwargs) #open datasets into dictionary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.89% [2/106 00:02&lt;02:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m cat_data\u001b[38;5;241m.\u001b[39mesmcat\u001b[38;5;241m.\u001b[39maggregation_control\u001b[38;5;241m.\u001b[39mgroupby_attrs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#to circumvent aggregate=false bug\u001b[39;00m\n\u001b[1;32m      3\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzarr_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m:{\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#doesn't actually aggregate if we set cmip6_cat.esmcat.aggregation_control.groupby_attrs = []\u001b[39;00m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m ddict \u001b[38;5;241m=\u001b[39m \u001b[43mcat_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataset_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#open datasets into dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/intake_esm/core.py:645\u001b[0m, in \u001b[0;36mesm_datastore.to_dataset_dict\u001b[0;34m(self, xarray_open_kwargs, xarray_combine_by_coords_kwargs, preprocess, storage_options, progressbar, aggregate, skip_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     gen \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_tasks)\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m         key, ds \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cat_data.esmcat.aggregation_control.groupby_attrs = [] #to circumvent aggregate=false bug\n",
    "\n",
    "kwargs = {\n",
    "    'zarr_kwargs':{\n",
    "        'consolidated':True,\n",
    "        'use_cftime':True\n",
    "    },\n",
    "    'aggregate':True #to avoid this issue: https://github.com/intake/intake-esm/issues/496\n",
    "    #doesn't actually aggregate if we set cmip6_cat.esmcat.aggregation_control.groupby_attrs = []\n",
    "}\n",
    "\n",
    "ddict = cat_data.to_dataset_dict(**kwargs) #open datasets into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6800109-de26-48fe-9d4d-c14a64cb75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddict_manual = {k.split('/')[-1].replace('.zarr',''):xr.open_dataset(fs.get_mapper(k),engine='zarr',chunks={}) for k in fs.ls('leap-persistent/jbusecke/data/CMIP6/manual_test')}\n",
    "ddict_manual = {k.split('/')[-1].replace('.zarr',''):xr.open_dataset(fs.get_mapper(k),engine='zarr',chunks={}) for k in fs.ls('leap-persistent/jbusecke/data/CMIP6/dataflow_test_production')}\n",
    "\n",
    "#do preprocessing\n",
    "\n",
    "#chunking structure changed, 100mb, smarter, if problems inform Julius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521777aa-e6e0-4ed3-ac31-d1c444180873",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ddict_manual.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769a6a5-dbb9-42d8-8119-81d044abce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename xmip possible\n",
    "ddict = drop_duplicate_timesteps(ddict) #CESM2-WACCM has duplicate timeseries\n",
    "ddict = preselect_years(ddict,1850,2100) #for now, limit analysis to up to 2100\n",
    "ddict = drop_coords(ddict,['bnds','nbnd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13a64d-6db0-4b70-8f25-7a808e99b883",
   "metadata": {},
   "source": [
    "Merge queried variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d613d7-8240-489d-b908-0b85f16b8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}): #join=outer pads NaNs which result in large chunks for timeseries that differ in length\n",
    "    ddict_merged = combine_datasets(ddict,merge_variables_aligning_lonlat,match_attrs=['source_id', 'grid_label', 'experiment_id', 'table_id','variant_label'])\n",
    "    #ddict_concat = combine_datasets(ddict_merged,concat_members_aligning_lonlat,match_attrs=['source_id', 'grid_label', 'experiment_id', 'table_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92478f-f7ec-4177-878f-efe18bd294f0",
   "metadata": {},
   "source": [
    "Do the regridding & subsetting. First, determine the grid coordinates around each tide gauge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba17baf-805b-4e10-a073-7c5217cca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrcoefs = xr.open_dataset('/home/jovyan/CMIP6cf/gssr_coefs_1degRes_forcing.nc') #contains coordinates of and MLR coefficients at TGs\n",
    "\n",
    "era5_grid = xr.Dataset( #the ERA5 grid used to derive the MLR coefficients\n",
    "        {   \"longitude\": ([\"longitude\"], np.arange(-40,30,1)+1/2, {\"units\": \"degrees_east\"}),\n",
    "            \"latitude\": ([\"latitude\"], np.arange(70,10,-1)-1/2, {\"units\": \"degrees_north\"}),})\n",
    "\n",
    "#get coordinates of n x n degree grids around each tide gauge\n",
    "num_degr = 2\n",
    "lat_ranges = np.zeros((len(mlrcoefs.tg),2))\n",
    "lon_ranges = np.zeros((len(mlrcoefs.tg),2))\n",
    "\n",
    "for t,tg in enumerate(mlrcoefs.tg.values):\n",
    "    lat_ranges[t,:] = era5_grid.latitude[((era5_grid.latitude>=(mlrcoefs.sel(tg=tg).lat-num_degr/2)) & (era5_grid.latitude<=(mlrcoefs.sel(tg=tg).lat+num_degr/2)))][0:2]\n",
    "    lon_ranges[t,:] = era5_grid.longitude[((era5_grid.longitude>=(mlrcoefs.sel(tg=tg).lon-num_degr/2)) & (era5_grid.longitude<=(mlrcoefs.sel(tg=tg).lon+num_degr/2)))][0:2]\n",
    "\n",
    "#create da's to index the CMIP6 files with:\n",
    "lons_da = xr.DataArray(lon_ranges,dims=['tg','lon_around_tg'],coords={'tg':mlrcoefs.tg,'lon_around_tg':[0,1]})\n",
    "lats_da = xr.DataArray(lat_ranges,dims=['tg','lat_around_tg'],coords={'tg':mlrcoefs.tg,'lat_around_tg':[0,1]})\n",
    "\n",
    "target_grid = era5_grid.sel(latitude=slice(np.max(lats_da)+2,np.min(lats_da)-2),longitude=slice(np.min(lons_da)-2,np.max(lons_da)+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974653c-8138-4826-a9a2-6e6a05ebd70b",
   "metadata": {},
   "source": [
    "Now, loop over each model/grid (should be only 1 grid per model), and apply the model/grid-specific interpolation weights to each dataset belonging to that model/grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef1795-e316-4a3c-863c-0a8b90215a71",
   "metadata": {},
   "source": [
    "**Note:** It is probably more memory-efficient to loop over the tide gauges and regrid to each tide-gauge specific 2 by 2 degree grid, especially if considering larger domains. For now, we regrid to a subset of the ERA5 grid big enough to contain all tide-gauge specific grids (~20x20 grid points), and index the regridded dataset at the tide-gauge specific grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5ad8d0-456f-451b-90cd-d9a839350d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,ds in ddict_merged.items():\n",
    "    lon_coord = list(k for k in ds.dims if 'lon' in k)[0] #find lon/lat coordinate names\n",
    "    \n",
    "    ds.coords[lon_coord] = ((ds.coords[lon_coord] + 180) % 360) - 180 #wrap around 0\n",
    "    ds = ds.reindex({ lon_coord : np.sort(ds[lon_coord])})\n",
    "    ddict_merged[key] = ds\n",
    "\n",
    "ds_dict = {k: v for k, v in ddict_merged.items()}\n",
    "ddict_subsetted = {k: v for k, v in ddict_merged.items()}\n",
    "\n",
    "while len(ds_dict) > 0: #<- from xmip's combine_datasets\n",
    "    k = list(ds_dict.keys())[0]\n",
    "    ds = ds_dict.pop(k)\n",
    "    ds.attrs[\"original_key\"] = k\n",
    "    \n",
    "    matched_datasets = _match_datasets(ds, ds_dict, ['source_id', 'grid_label'], pop=True) #find datasets belonging to same model/grid\n",
    "  \n",
    "    regridder = xe.Regridder(matched_datasets[0],target_grid,'bilinear',ignore_degenerate=True) #interpolation weights for this grid\n",
    "    #use periodic to avoid wrapping myself?\n",
    "    \n",
    "    for matched_ds in matched_datasets:\n",
    "        first_ds,aligned_ds = xr.align(matched_datasets[0],matched_ds,join='override',exclude=['time','member_id','dcpp_init_year']) #make sure lon/lat coordinates are exactly the same\n",
    "        \n",
    "        aligned_ds = aligned_ds.isel(dcpp_init_year=0,drop=True) #get rid of dcpp_init_year dimension\n",
    "        ddict_subsetted[matched_ds.original_key] = regridder(aligned_ds,keep_attrs=True).sel(latitude=lats_da,longitude=lons_da) #regrid to target grid and add to ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ab0c4-fe02-4c8e-b0c3-f351a17cb085",
   "metadata": {},
   "source": [
    "Store the datasets (directories structured per model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b8061f-26d9-4f51-b6ce-02bf34c77e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddict_subsetted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key,ds \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mddict_subsetted\u001b[49m\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      2\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/CMIP6cf/output/subsetted_forcing/\u001b[39m\u001b[38;5;124m'\u001b[39m,ds\u001b[38;5;241m.\u001b[39msource_id)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ddict_subsetted' is not defined"
     ]
    }
   ],
   "source": [
    "for key,ds in tqdm(ddict_subsetted.items()):\n",
    "    #model_path = os.path.join('/home/jovyan/CMIP6cf/output/subsetted_data/forcing_gssr_tgs/',ds.source_id)\n",
    "    model_path = os.path.join('leap-persistent/timh37/CMIP6/subsetted_data/forcing_gssr_tgs/',ds.source_id)\n",
    "    #if not os.path.exists(model_path):\n",
    "    #    os.mkdir(model_path)\n",
    "    #ds.to_netcdf(os.path.join(model_path,key.replace('.','_')+'.nc'),mode='w')\n",
    "    ds.to_zarr(os.path.join('gs://',model_path,key.replace('.','_')+'.zarr'),mode='w')\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2a091-d065-4f87-905c-afd1d936b849",
   "metadata": {},
   "source": [
    "^Takes about ~1,5h excluding EC-Earth3, 6h for EC-Earth3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f681d-a3c7-40ea-852a-b721cb3b98b6",
   "metadata": {},
   "source": [
    "Code for listing the instance_id of runs with missing timesteps:\n",
    "```python\n",
    "for k,v in ddict.items():\n",
    "    if (len(v.time) < len(np.arange(1850,2015))*12*30):\n",
    "    #if len(v.time) < len(np.arange(2015,2101))*12*30:\n",
    "        print(v.attrs['intake_esm_attrs:zstore'][0:-1].replace('gs://cmip6/','').replace('/','.'))\n",
    "```\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
