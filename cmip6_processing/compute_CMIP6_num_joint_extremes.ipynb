{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8899c2-c522-42e0-aa61-ce53a758f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1705/201601525.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import fnmatch\n",
    "from tqdm.autonotebook import tqdm\n",
    "import dask\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() # equivalent to fsspec.fs('gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853c8e9b-73b2-47c3-9881-09abe4ce60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def po_t_of_refyear(da,threshold,refyear,dim):\n",
    "    return da.where(da>da.sel(window=refyear).quantile(threshold,dim=dim))\n",
    "            \n",
    "def rolling_max(da,window_len,dim):\n",
    "    return da.rolling({dim:window_len},center=True,min_periods=1).max()\n",
    "\n",
    "def sum_num_extremes_pmonth(extremes):\n",
    "    extremes_ = extremes.copy(deep=True) #boolean array (True or False joint extreme occurs on that day)\n",
    "    if len(extremes.time.shape)>1:\n",
    "        extremes_['time_in_window_idx'] = extremes_.time.dt.month.isel(window=0).values\n",
    "    else:\n",
    "        extremes_['time_in_window_idx'] = extremes_.time.dt.month.values\n",
    "    num_extremes_pmonth = extremes_.rename({'time_in_window_idx':'month'}).groupby('month').sum()\n",
    "    return num_extremes_pmonth        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be0e9a-7d00-4d95-b211-57e51b0467c6",
   "metadata": {},
   "source": [
    "Configure the bivariate sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e2303f-56de-45d6-9f19-0e31cf0af7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure bivariate sampling settings\n",
    "max_lag = 0 #days\n",
    "declus_window_len = 1 #days\n",
    "threshold = .99 #quantile\n",
    "\n",
    "output_yrs = np.arange(1960,2100,20)\n",
    "window_len=40 #may need to increase? indicate settings in output folder?\n",
    "\n",
    "ref_year = 2000 #period to to compute thresholds from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7b2052-47a6-49e3-9171-dc112fbf19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the CMIP6 input settings\n",
    "var1 = 'surge'\n",
    "var2 = 'pr'\n",
    "domain = 'tgs' #'europe' or 'tgs'\n",
    "\n",
    "var1_dir = 'leap-persistent/timh37/CMIP6/timeseries/'+var1+'_g2_'+domain\n",
    "var2_dir = 'leap-persistent/timh37/CMIP6/timeseries/'+var2+'_'+domain\n",
    "\n",
    "if domain == 'tgs':\n",
    "    input_is_gridded = False\n",
    "elif domain == 'europe':\n",
    "    input_is_gridded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57ca67d-4dd6-4eb7-bd54-d3f2d63df818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ACCESS-CM2_gn_day_ssp245.zarr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea3197915d74d31bc4594d47ca2bf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 138\u001b[0m\n\u001b[1;32m    133\u001b[0m     num_extremes_mem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mvar2\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_extremes_refWindow_futT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mdict\u001b[39m(window\u001b[38;5;241m=\u001b[39mwin)] \u001b[38;5;241m=\u001b[39m sum_num_extremes_pmonth(np\u001b[38;5;241m.\u001b[39misfinite(var2_peaks_fut_threshold))\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#changes in magnitude of 95% in each season            \u001b[39;00m\n\u001b[1;32m    136\u001b[0m num_extremes_mem[var1\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_p95\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat((var1_var2_data_wdws[var1]\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    137\u001b[0m                                               var1_var2_data_wdws[var1]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m6\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m--> 138\u001b[0m                                               var1_var2_data_wdws[var1]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(\u001b[43mvar1_var2_data_wdws\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m9\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    139\u001b[0m                                               var1_var2_data_wdws[var1]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m12\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m)),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m num_extremes_mem[var2\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_p95\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat((var1_var2_data_wdws[var2]\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    141\u001b[0m                                               var1_var2_data_wdws[var2]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m6\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    142\u001b[0m                                               var1_var2_data_wdws[var2]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m9\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    143\u001b[0m                                               var1_var2_data_wdws[var2]\u001b[38;5;241m.\u001b[39mwhere((np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mmod(var1_var2_data_wdws\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth,\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m12\u001b[39m))\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.95\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_in_window_idx\u001b[39m\u001b[38;5;124m'\u001b[39m)),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m num_extremes_mem \u001b[38;5;241m=\u001b[39m num_extremes_mem\u001b[38;5;241m.\u001b[39massign_coords({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDJF\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAM\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJJA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSON\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/accessor_dt.py:382\u001b[0m, in \u001b[0;36mDatetimeAccessor.month\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmonth\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_DataArray:\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The month as January=1, December=12\"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_date_field\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/accessor_dt.py:223\u001b[0m, in \u001b[0;36mTimeAccessor._date_field\u001b[0;34m(self, name, dtype)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 223\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_get_date_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_index_or_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m newvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\u001b[38;5;241m.\u001b[39mvariable\u001b[38;5;241m.\u001b[39mcopy(data\u001b[38;5;241m=\u001b[39mresult, deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\u001b[38;5;241m.\u001b[39m_replace(newvar, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/accessor_dt.py:122\u001b[0m, in \u001b[0;36m_get_date_field\u001b[0;34m(values, name, dtype)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m map_blocks(\n\u001b[1;32m    119\u001b[0m         access_method, values, name, dtype\u001b[38;5;241m=\u001b[39mdtype, new_axis\u001b[38;5;241m=\u001b[39mnew_axis, chunks\u001b[38;5;241m=\u001b[39mchunks\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccess_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/accessor_dt.py:81\u001b[0m, in \u001b[0;36m_access_through_series\u001b[0;34m(values, name)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m field_values\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m*\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     field_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_as_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m field_values\u001b[38;5;241m.\u001b[39mreshape(values\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/accessor.py:96\u001b[0m, in \u001b[0;36mPandasDelegate._add_delegate_accessors.<locals>._create_delegator_property.<locals>._getter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delegate_property_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/indexes/accessors.py:89\u001b[0m, in \u001b[0;36mProperties._delegate_property_get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[1;32m     87\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values()\n\u001b[0;32m---> 89\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# maybe need to upcast (ints)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/indexes/extension.py:71\u001b[0m, in \u001b[0;36m_inherit_from_data.<locals>.fget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:143\u001b[0m, in \u001b[0;36m_field_accessor.<locals>.f\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_date_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_creso\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(\n\u001b[1;32m    145\u001b[0m         result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_var1 = [k.split('/')[-1] for k in fs.ls(var1_dir)]\n",
    "models_var2 = [k.split('/')[-1] for k in fs.ls(var2_dir)]\n",
    "source_ids = sorted(list(set(models_var1) & set(models_var2))) #intersection of models\n",
    "\n",
    "for source_id in [k for k in source_ids if ~k.startswith('.')]: #loop over models\n",
    "  \n",
    "    var1_model_path = os.path.join(var1_dir,source_id)\n",
    "    var2_model_path = os.path.join(var2_dir,source_id)\n",
    "    \n",
    "    #sfcWind_exps = [s.split('_')[-1][0:-3] for s in os.listdir(sfcWind_path) if s.startswith('.')==False]\n",
    "    #pr_exps = [s.split('_')[-1][0:-3] for s in os.listdir(pr_path) if s.startswith('.')==False]\n",
    "    \n",
    "    #get experiment_id's\n",
    "    var1_exps = [s.split('/')[-1].split('_')[-1][0:-5] for s in fs.ls(var1_model_path) if s.startswith('.')==False] \n",
    "    var2_exps = [s.split('/')[-1].split('_')[-1][0:-5] for s in fs.ls(var2_model_path) if s.startswith('.')==False]\n",
    "    experiment_ids = list(set(var1_exps) & set(var2_exps))\n",
    "\n",
    "    for experiment_id in experiment_ids: #loop over experiments\n",
    "        #load data:\n",
    "        fn = fnmatch.filter(fs.ls(var1_model_path),'*'+experiment_id+'*')[0]\n",
    "        fn = fn.split('/')[-1]\n",
    "        print('Processing file: '+fn)\n",
    "        if input_is_gridded==False:\n",
    "            var1_var2_data = xr.open_mfdataset((os.path.join('gs://',var1_model_path,fn),os.path.join('gs://',var2_model_path,fn)),engine='zarr',compat='override',chunks={'member_id':1,'time':100000})\n",
    "        else:\n",
    "            #sfcWind_pr = xr.open_mfdataset((os.path.join(sfcWind_path,fn),os.path.join(pr_path,fn)),chunks={'member_id':1,'time':100000,'longitude':3})#.sel(longitude=np.arange(-25,11))\n",
    "            var1_var2_data = xr.open_mfdataset((os.path.join('gs://',var1_model_path,fn),os.path.join('gs://',var2_model_path,fn)),engine='zarr',chunks={'member_id':1,'time':100000,'longitude':5})\n",
    " \n",
    "        #generate output paths\n",
    "        #model_path = os.path.join('/home/jovyan/CMIP6cf/output/dependence/sfcWind_pr_europe/40yr_p98_lag0d_declus1d_ref2000',sfcWind_pr.source_id)\n",
    "        output_path = '/home/jovyan/CMIP6cex/output/num_extremes/'+var1+'_g2_'+var2+'_'+var1_dir.split('_')[-1]+'/'+str(window_len)+'yr_'+str(threshold).replace('0.','p')+'_lag'+str(max_lag)+'d_declus'+str(declus_window_len)+'d_ref'+str(ref_year)\n",
    "        output_model_path = os.path.join(output_path,var1_var2_data.source_id)\n",
    "        output_fn = os.path.join(output_model_path,fn.replace('.zarr','.nc'))\n",
    "\n",
    "        #construct time window indices\n",
    "        if len(np.unique(var1_var2_data.time.resample(time='1Y').count()))>1: #remove leap days so that each computation window has the same length\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "                var1_var2_data = var1_var2_data.sel(time=~((var1_var2_data.time.dt.month == 2) & (var1_var2_data.time.dt.day == 29))) #^probably (hopefully) only has a small effect on the results\n",
    "        \n",
    "        days_in_year = int(var1_var2_data.time.resample(time='1Y').count()[0])\n",
    "        \n",
    "        if window_len%2 !=0: #odd\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(np.floor(window_len/2)))\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        else: #even\n",
    "            window_start_idx = days_in_year*(output_yrs-1850-int(window_len/2)+1)\n",
    "            first_window_idx = np.arange(0*days_in_year,window_len*days_in_year)\n",
    "        \n",
    "        if np.max(first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:])>=len(var1_var2_data.time): #if window exceeds simulation length\n",
    "            continue #skip\n",
    "            #raise Exception('Windows exceed simulation length.')\n",
    "            \n",
    "        window_idx = xr.DataArray( #indices of windows\n",
    "            data=first_window_idx[:,np.newaxis]+window_start_idx[np.newaxis,:],\n",
    "            dims=[\"time_in_window_idx\",\"window\"],\n",
    "            coords=dict(\n",
    "                time_in_window_idx=first_window_idx,\n",
    "                window=output_yrs\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "        if not os.path.exists(output_model_path):\n",
    "            os.mkdir(output_model_path)\n",
    "            \n",
    "        for m,member in tqdm(enumerate(var1_var2_data.member_id)): #loop over members of each model to compute the dependence\n",
    "        \n",
    "            var1_var2_data_mem = var1_var2_data.sel(member_id=member)\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "                var1_var2_data_wdws = var1_var2_data_mem.isel(time=window_idx) #select data in user-defined time windows\n",
    "            \n",
    "            data_is_complete = np.isfinite(var1_var2_data_wdws[var1]).all(dim='time_in_window_idx') * np.isfinite(var1_var2_data_wdws[var2]).all(dim='time_in_window_idx') #check data-completeness in each window\n",
    "\n",
    "            #derive peaks\n",
    "            var1_peaks = po_t_of_refyear(var1_var2_data_wdws[var1],threshold,ref_year,dim='time_in_window_idx')\n",
    "            var2_peaks = po_t_of_refyear(var1_var2_data_wdws[var2],threshold,ref_year,dim='time_in_window_idx')\n",
    "            \n",
    "            var1_peaks_declustered = var1_peaks.where(var1_peaks==var1_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            var2_peaks_declustered = var2_peaks.where(var2_peaks==var2_peaks.rolling({'time_in_window_idx':declus_window_len},center=True,min_periods=1).max(skipna=True))\n",
    "            \n",
    "            #determine joint extremes within 'max_lag' lag from eachother\n",
    "            joint_extremes = np.isfinite((rolling_max(var2_peaks_declustered,max_lag*2+1,dim='time_in_window_idx')*var1_peaks_declustered)) #previously: 'co_occurring'\n",
    "            \n",
    "            #generate output dataset for current member\n",
    "            num_extremes_mem = sum_num_extremes_pmonth(joint_extremes).to_dataset(name='num_joint_extremes')\n",
    "            num_extremes_mem['num_'+var1+'_extremes'] = sum_num_extremes_pmonth(np.isfinite(var1_peaks_declustered))\n",
    "            num_extremes_mem['num_'+var2+'_extremes'] = sum_num_extremes_pmonth(np.isfinite(var2_peaks_declustered))\n",
    "            \n",
    "            ####DECOMPOSITION OF CHANGES (probably not correct if declustering!!):\n",
    "            #1) sort (in magnitude) values in reference period to determine the equivalent threshold percentiles in other windows\n",
    "            if input_is_gridded:\n",
    "                sorted_var1_ref = xr.DataArray(data=np.sort(var1_var2_data_wdws.sel(window=ref_year)[var1],axis=0),dims=['time_in_window_idx','latitude','longitude'],\n",
    "                                                   coords=dict(time_in_window_idx=var1_var2_data_wdws.time_in_window_idx,latitude=var1_var2_data_wdws.latitude,longitude=var1_var2_data_wdws.longitude)).chunk({'longitude':5})\n",
    "                sorted_var2_ref = xr.DataArray(data=np.sort(var1_var2_data_wdws.sel(window=ref_year)[var2],axis=0),dims=['time_in_window_idx','latitude','longitude'],\n",
    "                                              coords=dict(time_in_window_idx=var1_var2_data_wdws.time_in_window_idx,latitude=var1_var2_data_wdws.latitude,longitude=var1_var2_data_wdws.longitude)).chunk({'longitude':5})\n",
    "            else:\n",
    "                sorted_var1_ref = xr.DataArray(data=np.sort(var1_var2_data_wdws.sel(window=ref_year)[var1],axis=0),dims=['time_in_window_idx','tg'],\n",
    "                                                   coords=dict(time_in_window_idx=var1_var2_data_wdws.time_in_window_idx,tg=var1_var2_data_wdws.tg))\n",
    "                sorted_var2_ref = xr.DataArray(data=np.sort(var1_var2_data_wdws.sel(window=ref_year)[var2],axis=0),dims=['time_in_window_idx','tg'],\n",
    "                                              coords=dict(time_in_window_idx=var1_var2_data_wdws.time_in_window_idx,tg=var1_var2_data_wdws.tg))\n",
    "            #initialize output arrays\n",
    "            num_extremes_mem['num_joint_extremes_'+var1+'_driven'] = num_extremes_mem['num_joint_extremes'].copy(deep=True)\n",
    "            num_extremes_mem['num_joint_extremes_'+var2+'_driven'] = num_extremes_mem['num_joint_extremes'].copy(deep=True)\n",
    "            num_extremes_mem['num_joint_extremes_'+var1+'_'+var2+'_driven'] = num_extremes_mem['num_joint_extremes'].copy(deep=True)\n",
    "            num_extremes_mem['num_'+var1+'_extremes_refWindow_futT'] = num_extremes_mem['num_'+var1+'_extremes'].copy(deep=True)\n",
    "            num_extremes_mem['num_'+var2+'_extremes_refWindow_futT'] = num_extremes_mem['num_'+var2+'_extremes'].copy(deep=True)\n",
    "            \n",
    "            for w,win in enumerate(var1_var2_data_wdws.window): #loop over each window to do the decomposition\n",
    "                #2) find the threshold values in the reference period corresponding to the percentile of events exceeding the reference threshold values in the future (var_{U_{var}}^{hist} in the paper)\n",
    "                var1_eqv_thresholds = sorted_var1_ref.isel(time_in_window_idx=-1*(np.isfinite(var1_peaks_declustered).sum(dim='time_in_window_idx').sel(window=win).load()))\n",
    "                var2_eqv_thresholds = sorted_var2_ref.isel(time_in_window_idx=-1*(np.isfinite(var2_peaks_declustered).sum(dim='time_in_window_idx').sel(window=win).load()))\n",
    "                \n",
    "                #3) determine the peaks above those threshold values in the reference window\n",
    "                var1_peaks_fut_threshold = var1_var2_data_wdws[var1].sel(window=ref_year).where(var1_var2_data_wdws[var1].sel(window=ref_year)>=var1_eqv_thresholds) #determine the peaks in the reference period above those values\n",
    "                var2_peaks_fut_threshold = var1_var2_data_wdws[var2].sel(window=ref_year).where(var1_var2_data_wdws[var2].sel(window=ref_year)>=var2_eqv_thresholds)\n",
    "\n",
    "                #4) determine the joint extremes for different components:\n",
    "                # a) var2 peaks above standard threshold in reference period, var1 above future threshold percentile in reference period\n",
    "                joint_extremes_var1_driven = np.isfinite((rolling_max(var2_peaks_declustered.sel(window=ref_year),max_lag*2+1,dim='time_in_window_idx')*var1_peaks_fut_threshold))\n",
    "\n",
    "                # b) var1 peaks above standard threshold in reference period, var2 above future threshold percentile in reference period\n",
    "                joint_extremes_var2_driven = np.isfinite((rolling_max(var2_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*var1_peaks_declustered.sel(window=ref_year)))\n",
    "\n",
    "                # c) var1 and var 2 above future threshold percentile in reference period\n",
    "                joint_extremes_var1_var2_driven = np.isfinite((rolling_max(var2_peaks_fut_threshold,max_lag*2+1,dim='time_in_window_idx')*var1_peaks_fut_threshold))\n",
    "           \n",
    "                #count per month\n",
    "                num_extremes_mem['num_joint_extremes_'+var1+'_driven'].loc[dict(window=win)] = sum_num_extremes_pmonth(joint_extremes_var1_driven)\n",
    "                num_extremes_mem['num_joint_extremes_'+var2+'_driven'].loc[dict(window=win)] = sum_num_extremes_pmonth(joint_extremes_var2_driven)\n",
    "                num_extremes_mem['num_joint_extremes_'+var1+'_'+var2+'_driven'].loc[dict(window=win)] = sum_num_extremes_pmonth(joint_extremes_var1_var2_driven)\n",
    "                num_extremes_mem['num_'+var1+'_extremes_refWindow_futT'].loc[dict(window=win)] = sum_num_extremes_pmonth(np.isfinite(var1_peaks_fut_threshold))\n",
    "                num_extremes_mem['num_'+var2+'_extremes_refWindow_futT'].loc[dict(window=win)] = sum_num_extremes_pmonth(np.isfinite(var2_peaks_fut_threshold))\n",
    "            \n",
    "            #store metadata\n",
    "            num_extremes_mem['complete_window'] = data_is_complete #store where windows miss data\n",
    "                        \n",
    "            num_extremes_mem = num_extremes_mem.expand_dims(dim={\"member_id\": 1}) #add coordinates & dimensions\n",
    "\n",
    "            num_extremes_mem.attrs = var1_var2_data.attrs #keep original attributes and add information on the extremes analysis\n",
    "            num_extremes_mem.attrs['window_length'] = str(window_len)\n",
    "            num_extremes_mem.attrs['declustering'] = 'Rolling window of '+str(declus_window_len)+' days'\n",
    "            num_extremes_mem.attrs['allowed_lag'] = str(max_lag)\n",
    "            num_extremes_mem.attrs['ref_window'] = str(ref_year)\n",
    "            \n",
    "            num_extremes_mem.to_netcdf(output_fn.replace('.nc','_'+num_extremes_mem.member_id.values[0]+'.nc'),mode='w')\n",
    "            num_extremes_mem.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197aaa1-6a91-4044-8ae8-08822f309b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
