{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc315e-ee78-4daa-90d2-caab58fceb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import dask\n",
    "import intake\n",
    "import fsspec\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.postprocessing import combine_datasets, _match_datasets,_concat_sorted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076a1f3-7194-4f91-bcd8-93dad0674e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '/home/jovyan/CMIP6cf/output/subsetted_pr/'\n",
    "\n",
    "ddict = defaultdict(dict)\n",
    "\n",
    "for source_id in [s for s in os.listdir(in_dir) if s.startswith('.')==False]:\n",
    "    \n",
    "    experiment_ids = [s.split('_')[2] for s in os.listdir(os.path.join(in_dir,source_id)) if s.startswith('.')==False]\n",
    "    for experiment_id in set(experiment_ids): #for each experiment_id, open the datasets, concatenating all realizations:\n",
    "        \n",
    "        source_ds = xr.open_mfdataset(os.path.join(in_dir,source_id,'*'+experiment_id+'*.nc'),join='outer',combine='nested',\n",
    "                                      compat='override',coords='minimal',concat_dim='member_id') #need to test this for large np. of realizations, like EC-Earth3\n",
    "        ddict[source_ds.original_key.rsplit('.',1)[0]] = source_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec14d0-d43a-449c-9d35-8a268a8f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssps = set([k.split('.')[2] for k in ddict.keys() if 'ssp' in k])\n",
    "\n",
    "ddict_concat = defaultdict(dict)\n",
    "\n",
    "for ssp in ssps:\n",
    "    ddict_ssp = defaultdict(dict)\n",
    "    \n",
    "    for k in ddict.keys():\n",
    "        if ((ssp in k) or ('historical' in k)):\n",
    "            ddict_ssp[k] = ddict[k]\n",
    "            \n",
    "    #append SSP to historical, only for realizations for which both experiments are provided (join=inner)\n",
    "    hist_ssp = combine_datasets(ddict_ssp,\n",
    "                                _concat_sorted_time,\n",
    "                                match_attrs =['source_id', 'grid_label','table_id'],combine_func_kwargs={'join':'inner'})\n",
    "    \n",
    "    for key,ds in hist_ssp.items(): #put back together in dictionary\n",
    "        ddict_concat[key+'.'+ssp] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc8510-9ef4-4e00-8d6f-a5793db3d267",
   "metadata": {},
   "source": [
    "Store (per SSP or all together? all together is easier for later, but may give quite large files?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8bee-abd9-471f-b2ba-8245ea76969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,ds in tqdm(ddict_concat.items()):\n",
    "    model_path = os.path.join('/home/jovyan/CMIP6cf/output/pr_timeseries/',ds.source_id)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.mkdir(model_path)\n",
    "    ds.to_netcdf(os.path.join(model_path,key.replace('.','_')+'.nc'),mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
