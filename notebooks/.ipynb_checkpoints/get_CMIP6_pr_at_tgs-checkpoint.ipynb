{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0ff811-96d3-4c4b-ae9c-5c34ea682794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import intake\n",
    "import fsspec\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.preprocessing import combined_preprocessing,_drop_coords\n",
    "from xmip.postprocessing import merge_variables, combine_datasets, concat_experiments,_concat_sorted_time\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275aec62-ab17-43c9-bea6-ba3917c6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_units_to_m(ddict_in):\n",
    "    ddict_out = ddict_in\n",
    "    for k, v in ddict_in.items():\n",
    "        \n",
    "        assert v.pr.units == 'kg m-2 s-1'\n",
    "        \n",
    "        #convert 'kg m-2 s-1' to daily accumulated 'm'\n",
    "        with xr.set_options(keep_attrs=True): \n",
    "            v['pr'] = 24*3600*v['pr']/1000 #multiply by number of seconds in a day to get to kg m-2, and divide by density (kg/m3) to get to m    \n",
    "        v.pr.attrs['units'] = 'm'\n",
    "        \n",
    "        ddict_out[k] = v\n",
    "        \n",
    "    return ddict_out\n",
    "\n",
    "def preselect_years(ddict_in,start_year,end_year):\n",
    "    ddict_out = defaultdict(dict)\n",
    "    \n",
    "    if start_year>=end_year:\n",
    "        raise Exception(\"Start year must come before end year.\")\n",
    "    \n",
    "    if start_year>2014: #only using SSP\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'ssp' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), str(end_year)))\n",
    "                \n",
    "    elif end_year<=2014: #only using historical\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'historical' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), str(end_year)))\n",
    "                \n",
    "    elif ((start_year<=2014) & (end_year>2014)): #using both\n",
    "        for k, v in ddict_in.items():\n",
    "            if 'ssp' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(None, str(end_year)))\n",
    "            elif 'historical' in k:\n",
    "                ddict_out[k] = v.sel(time=slice(str(start_year), None))\n",
    "    return ddict_out #NB: may result in no timesteps being selected at all\n",
    "\n",
    "def drop_duplicate_timesteps(ddict_in):\n",
    "    ddict_out = ddict_in\n",
    "    for k, v in ddict_in.items():\n",
    "        \n",
    "        unique_time, idx = np.unique(v.time,return_index=True)\n",
    "        \n",
    "        if len(v.time) != len(unique_time):\n",
    "            ddict_out[k] = v.isel(time=idx)\n",
    "            print('Dropping duplicate timesteps for:' + k)\n",
    "            \n",
    "    return ddict_out\n",
    "\n",
    "def drop_coords(ddict_in,coords_to_drop):\n",
    "    \n",
    "    for k, v in ddict_in.items():\n",
    "        \n",
    "        ddict_in[k] = v.drop_dims(coords_to_drop,errors=\"ignore\")\n",
    "          \n",
    "    return ddict_in\n",
    "\n",
    "def concat_realizations_most_common_ipf(ds_list):\n",
    "    '''custom function that concatenates only the realizations of the most common 'ipf' combination,\n",
    "    takes the first sorted 'ipf' if multiple 'ipf' are equally common'''\n",
    "    member_ids = [ds.member_id.data[0] for ds in ds_list]\n",
    "    \n",
    "    member_ids.sort() #often i1 is the baseline?\n",
    "\n",
    "    ipf_ids = [s[s.find('i'):] for s in member_ids] #separate 'ipf' from 'r'\n",
    "    from collections import Counter\n",
    "\n",
    "    most_common_ipf = Counter(ipf_ids).most_common()[0][0]\n",
    "\n",
    "    # find unique members and decide which values of 'ipf' give the most members/variants?\n",
    "    # pick only the matching datasets from the list\n",
    "    ds_pick = [ds for ds in ds_list if (most_common_ipf in ds.member_id.data[0])]\n",
    "    \n",
    "    #not ideal way to ensure coordinates are the same, otherwise differences in coordinates are padded with nans if using {join='outer'}\n",
    "    for idx,ds in enumerate(ds_pick):\n",
    "        if idx==0:\n",
    "            lat = ds['lat']\n",
    "            lon = ds['lon']\n",
    "        if ((ds['lat'].shape==lat.shape) & (ds['lon'].shape==lon.shape)):\n",
    "            ds['lat'] = lat\n",
    "            ds['lon'] = lon\n",
    "        ds_pick[idx] = ds\n",
    "        \n",
    "    return xr.concat(ds_pick, dim='member_id', join='outer', coords='minimal',compat='override') #return xr.concat(ds_pick, dim='member_id')\n",
    "\n",
    "def select_grid_with_most_members(ds_list):  \n",
    "    num_members = np.array([len(ds.member_id) for ds in ds_list])\n",
    "  \n",
    "    return ds_list[np.argmax(num_members)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bed2f12-9b92-4110-aa12-7a045937e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_gridcells_nearest_to_tgs(tg_ds,ds):\n",
    "    '''\n",
    "    tg_ds = xr.DataSet containing 'lon' and 'lat' coordinates of tide gauges\n",
    "    ds    = xr.DataSet containing CMIP6 data to subset\n",
    "    '''\n",
    "    \n",
    "    lon_name = list(k for k in ds.dims if 'lon' in k)[0] #find lon/lat coordinate names\n",
    "    lat_name = list(k for k in ds.dims if 'lat' in k)[0]\n",
    "    \n",
    "    #compute distances between TG coordinates and grid cell centers\n",
    "    distances = 2*np.arcsin( np.sqrt(\n",
    "        np.sin( (np.pi/180) * 0.5*(ds[lat_name]-tg_ds.lat) )**2 +\n",
    "        np.cos((np.pi/180)*tg_ds.lat)*np.cos((np.pi/180)*ds[lat_name])*np.sin((np.pi/180)*0.5*(ds[lon_name]-tg_ds.lon))**2) )\n",
    "    \n",
    "    idx_nearest = distances.argmin(dim=[lon_name,lat_name]) #find indices of nearest grid cells\n",
    "    ds_subsetted = ds[idx_nearest] #subset ds at nearest grid cells\n",
    "    \n",
    "    ds_subsetted = ds_subsetted.rename_vars({'lon':'gridcell_lon','lat':'gridcell_lat'}) #keep coordinates of nearest grid cells\n",
    "    ds_subsetted = ds_subsetted.assign_coords(lon=tg_ds.lon,lat=tg_ds.lat) #replace coordinates with TG coordinates\n",
    "    \n",
    "    return ds_subsetted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e4d6c24-cedc-439a-b12c-30110aaaa899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332/1688399918.py:25: DeprecationWarning: cdf_kwargs and zarr_kwargs are deprecated and will be removed in a future version. Please use xarray_open_kwargs instead.\n",
      "  ddict = cat_data.to_dataset_dict(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "my_models = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','CMCC-ESM2','CMCC-CM2-SR5','EC-Earth3',\n",
    "                'GFDL-CM4','GFDL-ESM4','HadGEM3-GC31-MM','MIROC6','MPI-ESM1-2-HR','MRI-ESM2-0',\n",
    "                'NorESM2-MM','TaiESM1']\n",
    "'''\n",
    "my_models = ['GFDL-CM4']\n",
    "col = google_cmip_col()\n",
    "experiment_id='ssp585'\n",
    "source_id = my_models\n",
    "kwargs = {\n",
    "    'zarr_kwargs':{\n",
    "        'consolidated':True,\n",
    "        'use_cftime':True\n",
    "    },\n",
    "    'aggregate':False\n",
    "}\n",
    "\n",
    "cat_data = col.search(\n",
    "    source_id=source_id,\n",
    "    experiment_id=['historical','ssp585'],\n",
    "    table_id='day',\n",
    "    variable_id=['pr'],\n",
    "    require_all_on=['source_id', 'member_id','grid_label']\n",
    ")\n",
    "ddict = cat_data.to_dataset_dict(**kwargs)\n",
    "#ddict = cat_data.to_dataset_dict(**kwargs,preprocess=combined_preprocessing) # a lot of 'renaming failed' warnings here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9f6f1-8b0a-4e6a-922b-cc9461aba1c7",
   "metadata": {},
   "source": [
    "**NB: I don't seem to need any preprocessing. If I turn it on I get a lot of renaming failed warnings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9769a6a5-dbb9-42d8-8119-81d044abce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = pr_units_to_m(ddict)\n",
    "ddict = drop_duplicate_timesteps(ddict) #CESM2-WACCM has duplicate timeseries\n",
    "ddict = preselect_years(ddict,1850,2100)\n",
    "ddict = drop_coords(ddict,['bnds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda5ef23-aedd-40c2-a9fa-e5e841894898",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    ddict_concat_mem = combine_datasets(\n",
    "        ddict,\n",
    "        concat_realizations_most_common_ipf,\n",
    "        match_attrs=['source_id', 'grid_label', 'experiment_id', 'table_id']\n",
    "    )\n",
    "#NB: This leaves multiple datasets for the same model with different grid labels. Probably need function to keep grid label with most variants?\n",
    "# Since this occurs only for a few models it is probably OK to just save these and remove them later?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c494a1-14ed-4d4a-817e-935bd155cc95",
   "metadata": {},
   "source": [
    "**NB: Padding with NaNs above creates large time chunks for runs with missing timesteps. When loading this data into memory the kernel seems to crash. How to solve?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed91f71-417a-416a-8e6c-f8e0957bbae9",
   "metadata": {},
   "source": [
    "**NB: `concat_realizations_most_common_ipf()` keeps multiple datasets for the same model with different grid labels. May be useful to filter these out too later, but it only occurs for a few models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76527442-521e-4730-95e7-09e3dcc9b58b",
   "metadata": {},
   "source": [
    "Combine the historical and ssp data if desired (**need custom combination if quering multiple SSPs at once?**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e410a3f9-881f-43c4-9996-8ebf4bbdc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict_concat = combine_datasets(ddict_concat_mem,\n",
    "                        _concat_sorted_time,\n",
    "                       match_attrs =['source_id', 'grid_label','table_id'] ) #appends SSP to historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a210d0f-cc16-43a7-b278-f436db7d03cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GFDL-CM4.gr2.day': <xarray.Dataset>\n",
       " Dimensions:         (lat: 90, lon: 144, member_id: 1, dcpp_init_year: 1,\n",
       "                      time: 91615)\n",
       " Coordinates:\n",
       "   * lat             (lat) float64 -89.0 -87.0 -85.0 -83.0 ... 85.0 87.0 89.0\n",
       "   * lon             (lon) float64 1.25 3.75 6.25 8.75 ... 353.8 356.2 358.8\n",
       "   * time            (time) object 1850-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "   * member_id       (member_id) object 'r1i1p1f1'\n",
       "   * dcpp_init_year  (dcpp_init_year) float64 nan\n",
       " Data variables:\n",
       "     pr              (member_id, dcpp_init_year, time, lat, lon) float64 dask.array<chunksize=(1, 1, 600, 90, 144), meta=np.ndarray>\n",
       " Attributes: (12/62)\n",
       "     Conventions:                      CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "     activity_id:                      CMIP\n",
       "     branch_method:                    standard\n",
       "     branch_time_in_child:             0.0\n",
       "     branch_time_in_parent:            36500.0\n",
       "     comment:                          <null ref>\n",
       "     ...                               ...\n",
       "     intake_esm_attrs:variable_id:     pr\n",
       "     intake_esm_attrs:grid_label:      gr2\n",
       "     intake_esm_attrs:zstore:          gs://cmip6/CMIP6/CMIP/NOAA-GFDL/GFDL-CM...\n",
       "     intake_esm_attrs:version:         20180701\n",
       "     intake_esm_attrs:_data_format_:   zarr\n",
       "     intake_esm_dataset_key:           CMIP.NOAA-GFDL.GFDL-CM4.historical.r1i1...,\n",
       " 'GFDL-CM4.gr1.day': <xarray.Dataset>\n",
       " Dimensions:         (lat: 180, lon: 288, member_id: 1, dcpp_init_year: 1,\n",
       "                      time: 91615)\n",
       " Coordinates:\n",
       "   * lat             (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 87.5 88.5 89.5\n",
       "   * lon             (lon) float64 0.625 1.875 3.125 4.375 ... 356.9 358.1 359.4\n",
       "   * time            (time) object 1850-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "   * member_id       (member_id) object 'r1i1p1f1'\n",
       "   * dcpp_init_year  (dcpp_init_year) float64 nan\n",
       " Data variables:\n",
       "     pr              (member_id, dcpp_init_year, time, lat, lon) float64 dask.array<chunksize=(1, 1, 600, 180, 288), meta=np.ndarray>\n",
       " Attributes: (12/63)\n",
       "     Conventions:                      CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "     activity_id:                      CMIP\n",
       "     branch_method:                    standard\n",
       "     branch_time_in_child:             0.0\n",
       "     branch_time_in_parent:            36500.0\n",
       "     comment:                          <null ref>\n",
       "     ...                               ...\n",
       "     intake_esm_attrs:grid_label:      gr1\n",
       "     intake_esm_attrs:zstore:          gs://cmip6/CMIP6/CMIP/NOAA-GFDL/GFDL-CM...\n",
       "     intake_esm_attrs:version:         20180701\n",
       "     intake_esm_attrs:_data_format_:   zarr\n",
       "     intake_esm_dataset_key:           CMIP.NOAA-GFDL.GFDL-CM4.historical.r1i1...\n",
       "     original_key:                     GFDL-CM4.gr1.day}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b36f6e6-e625-4a2d-9953-66714add78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = combine_datasets(ddict_concat,select_grid_with_most_members,match_attrs =['source_id','table_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e4966f4-262c-4b55-b9f5-54c289f1cb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GFDL-CM4.day': <xarray.Dataset>\n",
       " Dimensions:         (lat: 90, lon: 144, member_id: 1, dcpp_init_year: 1,\n",
       "                      time: 91615)\n",
       " Coordinates:\n",
       "   * lat             (lat) float64 -89.0 -87.0 -85.0 -83.0 ... 85.0 87.0 89.0\n",
       "   * lon             (lon) float64 1.25 3.75 6.25 8.75 ... 353.8 356.2 358.8\n",
       "   * time            (time) object 1850-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "   * member_id       (member_id) object 'r1i1p1f1'\n",
       "   * dcpp_init_year  (dcpp_init_year) float64 nan\n",
       " Data variables:\n",
       "     pr              (member_id, dcpp_init_year, time, lat, lon) float64 dask.array<chunksize=(1, 1, 600, 90, 144), meta=np.ndarray>\n",
       " Attributes: (12/62)\n",
       "     Conventions:                      CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "     activity_id:                      CMIP\n",
       "     branch_method:                    standard\n",
       "     branch_time_in_child:             0.0\n",
       "     branch_time_in_parent:            36500.0\n",
       "     comment:                          <null ref>\n",
       "     ...                               ...\n",
       "     intake_esm_attrs:variable_id:     pr\n",
       "     intake_esm_attrs:grid_label:      gr2\n",
       "     intake_esm_attrs:zstore:          gs://cmip6/CMIP6/CMIP/NOAA-GFDL/GFDL-CM...\n",
       "     intake_esm_attrs:version:         20180701\n",
       "     intake_esm_attrs:_data_format_:   zarr\n",
       "     intake_esm_dataset_key:           CMIP.NOAA-GFDL.GFDL-CM4.historical.r1i1...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92478f-f7ec-4177-878f-efe18bd294f0",
   "metadata": {},
   "source": [
    "Do the subsetting at grid cells nearest to the tide gauges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba17baf-805b-4e10-a073-7c5217cca98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae32df660c064694a5380e1b43700d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlrcoefs = xr.open_dataset('/home/jovyan/CMIP6cf/gssr_coefs_1degRes_forcing.nc') #contains coordinates of and MLR coefficients at TGs\n",
    "\n",
    "ddict_near_tgs = defaultdict(dict)\n",
    "\n",
    "for key,ds in tqdm(ddict_concat.items()):\n",
    "    ds = ds.isel(dcpp_init_year=0,drop=True)\n",
    "    ddict_near_tgs[key] = select_gridcells_nearest_to_tgs(mlrcoefs,ds)\n",
    "    #ds_nearest.load()\n",
    "    #store at this point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4807273f-ec10-4476-bcfc-67fdb20f5854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'MPI-ESM1-2-HR.gn.day': <xarray.Dataset>\n",
       "             Dimensions:       (tg: 109, member_id: 2, time: 91676)\n",
       "             Coordinates:\n",
       "                 gridcell_lat  (tg) float64 44.42 47.22 41.61 47.22 ... 50.03 51.9 43.48\n",
       "                 gridcell_lon  (tg) float64 359.1 358.1 1.875 358.1 ... 354.4 355.3 354.4\n",
       "               * time          (time) object 1850-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "               * member_id     (member_id) object 'r1i1p1f1' 'r2i1p1f1'\n",
       "               * tg            (tg) object 'arcachon_eyrac_.csv' ... 'gijon_gijon_spain.csv'\n",
       "                 lat           (tg) float64 44.66 47.31 41.34 47.29 ... 58.44 50.1 51.7 43.56\n",
       "                 lon           (tg) float64 -1.164 -2.108 2.163 -2.0 ... -5.542 -5.014 -5.698\n",
       "             Data variables:\n",
       "                 pr            (member_id, time, tg) float64 dask.array<chunksize=(1, 264, 109), meta=np.ndarray>\n",
       "             Attributes: (12/64)\n",
       "                 Conventions:                      CF-1.7 CMIP-6.2\n",
       "                 activity_id:                      CMIP\n",
       "                 branch_method:                    standard\n",
       "                 branch_time_in_child:             0.0\n",
       "                 branch_time_in_parent:            0.0\n",
       "                 cmor_version:                     3.5.0\n",
       "                 ...                               ...\n",
       "                 intake_esm_attrs:grid_label:      gn\n",
       "                 intake_esm_attrs:zstore:          gs://cmip6/CMIP6/CMIP/MPI-M/MPI-ESM1-2-...\n",
       "                 intake_esm_attrs:version:         20190710\n",
       "                 intake_esm_attrs:_data_format_:   zarr\n",
       "                 intake_esm_dataset_key:           CMIP.MPI-M.MPI-ESM1-2-HR.historical.r1i...\n",
       "                 original_key:                     MPI-ESM1-2-HR.gn.historical.day})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict_near_tgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6c9c7-0e6c-4982-aafb-5966cbbdb82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
