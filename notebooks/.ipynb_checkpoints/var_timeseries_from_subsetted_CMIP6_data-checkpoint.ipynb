{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdc315e-ee78-4daa-90d2-caab58fceb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1531/283942508.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import dask\n",
    "import intake\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcf04a6-fddd-4255-82a9-924eb4487bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_coords(ddict_in,coords_to_drop):\n",
    "    for k, v in ddict_in.items():\n",
    "        ddict_in[k] = v.drop_dims(coords_to_drop,errors=\"ignore\")\n",
    "    return ddict_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ed4a2-9e62-45c1-ac03-17606c50c3a1",
   "metadata": {},
   "source": [
    "Loop over subsetted datasets and open them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6076a1f3-7194-4f91-bcd8-93dad0674e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set:\n",
    "in_dir = '/home/jovyan/CMIP6cf/output/subsetted_data/pr_europe/'\n",
    "out_dir = '/home/jovyan/CMIP6cf/output/timeseries/pr_europe/'\n",
    "\n",
    "ddict = defaultdict(dict)\n",
    "\n",
    "for source_id in [s for s in os.listdir(in_dir) if s.startswith('.')==False]:\n",
    "    \n",
    "    experiment_ids = [s.split('_')[2] for s in os.listdir(os.path.join(in_dir,source_id)) if s.startswith('.')==False]\n",
    "    for experiment_id in set(experiment_ids): #for each experiment_id, open the datasets, concatenating all realizations:\n",
    "        #with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "        source_ds = xr.open_mfdataset(os.path.join(in_dir,source_id,'*'+experiment_id+'*.nc'),join='outer',combine='nested',\n",
    "                                      compat='override',coords='minimal',concat_dim='member_id',chunks={'member_id':1,'longitude':5}) #need to test this for large np. of realizations, like EC-Earth3\n",
    "        \n",
    "        ddict[source_ds.original_key.rsplit('.',1)[0]] = source_ds\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e90a3-899e-4843-951e-9d86a7565fb1",
   "metadata": {},
   "source": [
    "Append SSP runs to historical runs for each SSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaec14d0-d43a-449c-9d35-8a268a8f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssps = set([k.split('.')[2] for k in ddict.keys() if 'ssp' in k])\n",
    "\n",
    "ddict_concat = defaultdict(dict)\n",
    "\n",
    "for ssp in ssps:\n",
    "    ddict_ssp = defaultdict(dict)\n",
    "    \n",
    "    for k in ddict.keys():\n",
    "        if ((ssp in k) or ('historical' in k)):\n",
    "            if k.replace('historical',ssp) in ddict.keys(): #only consider historical if there's also ssp\n",
    "                ddict_ssp[k] = ddict[k]\n",
    "            \n",
    "    #append SSP to historical, only for realizations for which both experiments are provided (join=inner)\n",
    "    hist_ssp = combine_datasets(ddict_ssp,\n",
    "                                _concat_sorted_time,\n",
    "                                match_attrs =['source_id', 'grid_label','table_id'],combine_func_kwargs={'join':'inner'})\n",
    "\n",
    "    for key,ds in hist_ssp.items(): #put back together in dictionary\n",
    "        ddict_concat[key+'.'+ssp] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc8510-9ef4-4e00-8d6f-a5793db3d267",
   "metadata": {},
   "source": [
    "Store per SSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8bee-abd9-471f-b2ba-8245ea76969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ff986319454fff98d005ba10664c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key,ds in tqdm(ddict_concat.items()):\n",
    "    model_path = os.path.join(out_dir,ds.source_id)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.mkdir(model_path)\n",
    "    ds.to_netcdf(os.path.join(model_path,key.replace('.','_')+'.nc'),mode='w')\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4f60-8659-4bed-886d-4da55f7bce99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
