{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0ff811-96d3-4c4b-ae9c-5c34ea682794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1797/2865278981.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import dask\n",
    "import intake\n",
    "import fsspec\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275aec62-ab17-43c9-bea6-ba3917c6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_bounds(ds):\n",
    "    \"\"\"Drop coordinates like 'time_bounds' from datasets,\n",
    "    which can lead to issues when merging.\"\"\"\n",
    "    drop_vars = [vname for vname in ds.coords\n",
    "                 if (('_bounds') in vname ) or ('_bnds') in vname]\n",
    "    return ds.drop(drop_vars)\n",
    "\n",
    "def open_dsets(df):\n",
    "    \"\"\"Open datasets from cloud storage and return xarray dataset.\"\"\"\n",
    "    dsets = [xr.open_zarr(fsspec.get_mapper(ds_url), consolidated=True)\n",
    "             .pipe(drop_all_bounds)\n",
    "             for ds_url in df.zstore]\n",
    "    try:\n",
    "        ds = xr.merge(dsets, join='exact')\n",
    "        return ds\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def open_delayed(df):\n",
    "    \"\"\"A dask.delayed wrapper around `open_dsets`.\n",
    "    Allows us to open many datasets in parallel.\"\"\"\n",
    "    return dask.delayed(open_dsets)(df)\n",
    "\n",
    "def regrid_to_era5(ds,era5_grid):\n",
    "    \"\"\"wrapper around xesmf regridding\"\"\"\n",
    "    regridder = xe.Regridder(ds,era5_grid,'bilinear')\n",
    "    \n",
    "    return regridder(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba17baf-805b-4e10-a073-7c5217cca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrcoefs = xr.open_dataset('CMIP6cf/gssr_coefs_1degRes_forcing.nc') #contains coordinates of and MLR coefficients around TGs\n",
    "\n",
    "era5_grid = xr.Dataset(\n",
    "        {\n",
    "            \"longitude\": ([\"longitude\"], np.arange(-40,30,1)+1/2, {\"units\": \"degrees_east\"}),\n",
    "            \"latitude\": ([\"latitude\"], np.arange(70,10,-1)-1/2, {\"units\": \"degrees_north\"}),\n",
    "        }\n",
    "    ) #grid of the ERA5 forcing used to derive the MLR coefficients\n",
    "\n",
    "#get coordinates of 2x2 degree grids around each tide gauge\n",
    "num_degr = 2\n",
    "lat_ranges = np.zeros((len(mlrcoefs.tg),2))\n",
    "lon_ranges = np.zeros((len(mlrcoefs.tg),2))\n",
    "\n",
    "for t,tg in enumerate(mlrcoefs.tg.values):\n",
    "    lat_ranges[t,:] = era5_grid.latitude[((era5_grid.latitude>=(mlrcoefs.sel(tg=tg).lat-num_degr/2)) & (era5_grid.latitude<=(mlrcoefs.sel(tg=tg).lat+num_degr/2)))][0:2]\n",
    "    lon_ranges[t,:] = era5_grid.longitude[((era5_grid.longitude>=(mlrcoefs.sel(tg=tg).lon-num_degr/2)) & (era5_grid.longitude<=(mlrcoefs.sel(tg=tg).lon+num_degr/2)))][0:2]\n",
    "\n",
    "#create da's to index the CMIP6 simulations with\n",
    "lons_da = xr.DataArray(lon_ranges,dims=['tg','lon_around_tg'],coords={'tg':mlrcoefs.tg,'lon_around_tg':[0,1]})\n",
    "lats_da = xr.DataArray(lat_ranges,dims=['tg','lat_around_tg'],coords={'tg':mlrcoefs.tg,'lat_around_tg':[0,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af57a7f-c149-4785-ba09-74a6e2d59857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#display all available (it would be nice to have a function that shows only those instances for which all queried aspects are available\\ncol_subset.df.groupby(\"source_id\")[\\n    [\"experiment_id\", \"variable_id\", \"table_id\",\"member_id\"]\\n].nunique()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open CMIP6 files\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "df.head()\n",
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "\n",
    "\n",
    "query0 = dict(\n",
    "    experiment_id=['ssp585'], \n",
    "    table_id='day',                            \n",
    "    variable_id=['sfcWind','psl']\n",
    ")\n",
    "\n",
    "col_subset = col.search(**query0)\n",
    "col_subset.df.groupby(\"source_id\")[\n",
    "    [\"experiment_id\", \"variable_id\", \"table_id\"]\n",
    "].nunique()\n",
    "\n",
    "query = dict(\n",
    "    experiment_id=['ssp585'], \n",
    "    table_id='day',                            \n",
    "    variable_id=['sfcWind','psl'], \n",
    "    member_id = ['r1i1p1f1','r2i1p1f1'],                \n",
    "    source_id=['MPI-ESM1-2-HR','MIROC6']\n",
    ")\n",
    "\"\"\"\n",
    "#display all available (it would be nice to have a function that shows only those instances for which all queried aspects are available\n",
    "col_subset.df.groupby(\"source_id\")[\n",
    "    [\"experiment_id\", \"variable_id\", \"table_id\",\"member_id\"]\n",
    "].nunique()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c340c9eb-ecfa-4a3c-9148-4e89c3fcd393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>DKRZ</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>DKRZ</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>DWD</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r2i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>DWD</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r2i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>MIROC</td>\n",
       "      <td>MIROC6</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>psl</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20191016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>MIROC</td>\n",
       "      <td>MIROC6</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>MIROC</td>\n",
       "      <td>MIROC6</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r2i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>sfcWind</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id institution_id      source_id experiment_id member_id table_id  \\\n",
       "0  ScenarioMIP           DKRZ  MPI-ESM1-2-HR        ssp585  r1i1p1f1      day   \n",
       "1  ScenarioMIP           DKRZ  MPI-ESM1-2-HR        ssp585  r1i1p1f1      day   \n",
       "2  ScenarioMIP            DWD  MPI-ESM1-2-HR        ssp585  r2i1p1f1      day   \n",
       "3  ScenarioMIP            DWD  MPI-ESM1-2-HR        ssp585  r2i1p1f1      day   \n",
       "4  ScenarioMIP          MIROC         MIROC6        ssp585  r1i1p1f1      day   \n",
       "5  ScenarioMIP          MIROC         MIROC6        ssp585  r1i1p1f1      day   \n",
       "6  ScenarioMIP          MIROC         MIROC6        ssp585  r2i1p1f1      day   \n",
       "\n",
       "  variable_id grid_label                                             zstore  \\\n",
       "0     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-H...   \n",
       "1         psl         gn  gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-H...   \n",
       "2     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR...   \n",
       "3         psl         gn  gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR...   \n",
       "4         psl         gn  gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...   \n",
       "5     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...   \n",
       "6     sfcWind         gn  gs://cmip6/CMIP6/ScenarioMIP/MIROC/MIROC6/ssp5...   \n",
       "\n",
       "   dcpp_init_year   version  \n",
       "0             NaN  20190710  \n",
       "1             NaN  20190710  \n",
       "2             NaN  20190710  \n",
       "3             NaN  20190710  \n",
       "4             NaN  20191016  \n",
       "5             NaN  20200323  \n",
       "6             NaN  20200323  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_subset = col.search(**query)\n",
    "overview=col_subset.df\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9d97f90-5b46-49b6-a251-1e9c53a8e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'MIROC6': {'ssp585': Delayed('open_dsets-35109469-a5f8-497e-b41c-be76193758ed')},\n",
       "             'MPI-ESM1-2-HR': {'ssp585': Delayed('open_dsets-0603db0e-ea69-4c52-bbe5-6c247d14658b')}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open datasets\n",
    "dsets = defaultdict(dict)\n",
    "\n",
    "for group, df in col_subset.df.groupby(by=['source_id', 'experiment_id']):\n",
    "    dsets[group[0]][group[1]] = open_delayed(df)\n",
    "dsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf6fc8-ee29-4da5-91af-38c18fd38810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "dsets_ = dask.compute(dict(dsets))[0] #here I run into memory problems if not separating the variants\n",
    "dsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be42e1-5a0a-41af-912c-4e9e3b8ab78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tqdm(dsets_.items()):\n",
    "    expt_dsets = v.values()\n",
    "    \n",
    "    for ds in expt_dsets:\n",
    "  \n",
    "        #change longitude coordinates (avoids getting NaNs at the 0-meridian)\n",
    "        lon_coord = list(k for k in ds.dims if 'lon' in k)[0] #find lon/lat coordinate names\n",
    "\n",
    "        ds.coords[lon_coord] = ((ds.coords[lon_coord] + 180) % 360) - 180 #wrap around 0\n",
    "        ds = ds.reindex({ lon_coord : np.sort(ds[lon_coord])})\n",
    "\n",
    "        regridded_ds = regrid_to_era5(ds,era5_grid) #regrid to same grid as ERA5\n",
    "        ds_around_tgs = regridded_ds.sel(latitude=lats_da,longitude=lons_da) #subset at num_degr by num_degr grids around TGs\n",
    "        #ds_around_tgs.to_netcdf('test.nc',mode='w') #save into single file (can save to individual tg files as well, just for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac5886-b164-4c93-a8e3-6ec876613744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ddb6c-3666-49f3-b603-7776772ded8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#change longitude coordinates (avoids getting NaNs at the 0-meridian)\n",
    "lon_coord = list(k for k in forcing.dims if 'lon' in k)[0] #find lon/lat coordinate names\n",
    "            \n",
    "forcing.coords[lon_coord] = ((forcing.coords[lon_coord] + 180) % 360) - 180 #wrap around 0\n",
    "forcing = forcing.reindex({ lon_coord : np.sort(forcing[lon_coord])})\n",
    "\n",
    "regridded_forcing = regrid_to_era5(forcing,era5_grid) #regrid to same grid as ERA5\n",
    "forcing_around_tgs = regridded_forcing.sel(latitude=lats_da,longitude=lons_da) #subset at num_degr by num_degr grids around TGs\n",
    "\n",
    "#test\n",
    "#normalized_forcing = normalized_forcing.stack(coord=['lon_around_tg','lat_around_tg'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64807d78-d56e-4fe7-83a5-5bbf2789317e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
